{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79d3999",
   "metadata": {},
   "source": [
    "# Conjunction Risk Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8ecfb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "From 2020 to 2024, satellites operating in Earth orbit grew from 3,371 to 11,539. In this year alone, more than 1,200 satellites were launched into orbit from January to April. SpaceX led with 573 Starlink satellites during the Q1 of 2025.\n",
    "\n",
    "Our space environment is becoming increasingly crowded as the number of satellites and large constellations like Starlink continues to grow. In addition to these new launches, inactive satellites in Low Earth Orbit (LEO) can remain in orbit for years to centuries. \n",
    "\n",
    "Each additional satellite increases conjunction frequency and thus creates more chances for collision. When two satellites collide, they can produce thousands of pieces of debris and trigger cascading collision events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e47c0a",
   "metadata": {},
   "source": [
    "Sources: \n",
    "- [Satellite Industry Association Releases the 28th Annual State of the Satellite Industry Report](https://sia.org/historic-number-of-launches-powers-commercial-satellite-industry-growth-satellite-industry-association-releases-the-28th-annual-state-of-the-satellite-industry-report/)\n",
    "- [Orbital debris and the market for satellites](https://www.sciencedirect.com/science/article/pii/S0921800923000940)\n",
    "- [Modeling Orbital Decay of Low-Earth Orbit Satellites due to Atmospheric Drag](https://arxiv.org/pdf/2508.19549)\n",
    "- [NASA Spacecraft Conjunction Assessment and Collision Avoidance Best Practices Handbook](https://ntrs.nasa.gov/api/citations/20230002470/downloads/CA_Handbook_CM%20Version%202-24-23.docx.pdf?utm_source=chatgpt.com)\n",
    "- [Satellite orbital conjunction reports assessing threatening encounters in space (SOCRATES)](https://conference.sdo.esoc.esa.int/proceedings/sdc4/paper/2/SDC4-paper2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347690a1",
   "metadata": {},
   "source": [
    "## Key Terms and Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e751bc",
   "metadata": {},
   "source": [
    "### 1. What is a shell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bdc8e",
   "metadata": {},
   "source": [
    "A shell is band of altitudes where satellites are placed. It is not as single orbit but a \"layer\" above Earth where satellites can exist with different inclinations and longitudes.\n",
    "\n",
    "**Risks of different shells:**\n",
    "\n",
    "- Shells below 500 km are less crowded, but satellites decay faster due to atmospheric drag.\n",
    "\n",
    "- Shells between 500–600 km very popular because they balance longer lifetime with lower launch cost. However, conjunctions risks are higher since the space is more crowded. Lifetime could be years to decades, e.g. a dead satellite at 550 km might remain in orbit for 10-25 years before atmospheric reentry.\n",
    "\n",
    "- There is less drag in shells above 800 km, so satellites can stay for decades to centuries. This is bad for long-term sustainability since debris also lingers forever.\n",
    "\n",
    "- Objects in the geostationary orbit shell (~36,000 km) remain essentially forever as there is meaningful drag at all. Satellites must be moved to a \"graveyard orbit\" when retired.\n",
    "\n",
    "**Lifetimes** \n",
    "\n",
    "Consider a typical satellite-sized object that is about 100–1,000 kg with moderate drag area.\n",
    "\n",
    "Below are its orbital lifetime estimates by altitude:\n",
    "\n",
    "- 300-400 km:           ~0-2 years before atmospheric reentry\n",
    "- 500-600 km:           ~5–30 years\n",
    "- 700-800 km:           ~80–400 years\n",
    "- 900-1,000 km:         ~500–1,500 years\n",
    "- 1,200 km and above:   2,000+ years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743244a",
   "metadata": {},
   "source": [
    "### 2. Space Object Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da744769",
   "metadata": {},
   "source": [
    "|*Object Type*|*Description*|*Importance in Conjunction Risk Analysis*|\n",
    "| - | - | - |\n",
    "|**Payload**|Operational or defunct satellites|Valuable, often maneuverable, critical to protect|\n",
    "|**Rocket body**|Spent propulsion units to deploy satellites into orbit, i.e. launch vehicle stages|Large, non-maneuverable, collision threat|\n",
    "|**Debris**|Fragments from explosions, collisions, breakups|Numerous and unpredictable|\n",
    "|**Unknown**|Identified but unclassified objects|Complicates modeling with uncertainty, could be a hazard or payload|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db38f4",
   "metadata": {},
   "source": [
    "Why are rocket bodies catalogued differently than standard debris?\n",
    "\n",
    "* From [Space Track Documentation](https://www.space-track.org/documentation#legend): \n",
    "\n",
    "    They can have mechanisms or fuel on board that can affect the orbital behavior of the rocket body even after long periods of time. Rocket bodies are also constructed to endure high temperatures and stresses associated with launch, so they have a greater probability of surviving reentry and require closer attention than most debris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f93c87",
   "metadata": {},
   "source": [
    "### 3. Conjunction vs. Collision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fa73f",
   "metadata": {},
   "source": [
    "Conjunction: A close approach between two objects in space, defined by a threshold distance. \n",
    "\n",
    "Collision: An event where wo objects hit each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ca853",
   "metadata": {},
   "source": [
    "## Historical Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f1075",
   "metadata": {},
   "source": [
    "### 2009 - The First Satellite Collision\n",
    "\n",
    "The [collision of Iridium 33 and Cosmos 2251](https://ntrs.nasa.gov/api/citations/20100002023/downloads/20100002023.pdf) produced more than 1800 pieces of debris that were larger than 10 cm. Some of which will remain in orbit through 2100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fd18a",
   "metadata": {},
   "source": [
    "## Goal: Forecast Conjunction Risk\n",
    "\n",
    "Phase 1: Setup\n",
    "\n",
    "- Define scope\n",
    "- Import libraries and dataset\n",
    "- Data wrangling \n",
    "- Configure conjunction analysis\n",
    "- Build propagators\n",
    "\n",
    "Phase 2: Execution\n",
    "\n",
    "- Run coarse propagation\n",
    "- Deduplicate coarse candidates\n",
    "- Refine locally\n",
    "\n",
    "Phase 3: Analysis and Reporting\n",
    "- Risk report\n",
    "- Summary and recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040166b0",
   "metadata": {},
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633847c7",
   "metadata": {},
   "source": [
    "*Objective*\n",
    "\n",
    "As satellites are being launched at an accelerating rate each year, we want to know: Is it getting too crowded in popular shells? Can we track or predict the risk of conjunctions? \n",
    "\n",
    "Our reported findings are intended to support policymakers in making evidence-based decisions regarding space safety and environmental regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b076ae8",
   "metadata": {},
   "source": [
    "*Dataset*\n",
    "\n",
    "We will work with a combined dataset from:\n",
    "\n",
    "1. United States Space Force (USSF)'s 18th Space Defense Squadron Element Sets\n",
    "2. NASA Goddard Space Flight Center's CDDIS (Crustal Dynamics Data Information System) Ephemeris Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfe8ce4",
   "metadata": {},
   "source": [
    "*Deliverable*\n",
    "\n",
    "Risk report and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f0b7a",
   "metadata": {},
   "source": [
    "*Model Choice*\n",
    "\n",
    "The `SGP4` is a standard orbital propagation model used to predict to position and velocity of satellites over time.\n",
    "\n",
    "- Strengths: fast, efficient, standardized\n",
    "- Limitations: not the most precise, best for short-term predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b479",
   "metadata": {},
   "source": [
    "*Methodology*\n",
    "\n",
    "1) What time horizon are we forecasting?\n",
    "    \n",
    "    Screen for close approaches over the next 24 hours.\n",
    "    This is long enough to see interesting traffic but short enough to run fast on a laptop with thousands of objects.\n",
    "\n",
    "2) How fine is our sampling of time?\n",
    "\n",
    "    For the first \"coarse\" pass, propagate every 5 minutes. For any potential close approach we find, we’ll re-check just those two satellites around that time at 30-second steps to refine the minimum distance. This will keep runtime manageable and still finds the real minimum distance accurately.\n",
    "\n",
    "3) What counts as a “conjunction”?\n",
    "\n",
    "    Flag pairs that ever get within 10 km (and we’ll also count the stricter 5 km subset). We’ll use an initial search radius of 20 km during the coarse pass to make sure we don’t miss events that dip below 10 km between 5-minute samples.\n",
    "\n",
    "4) Which objects are we analyzing?\n",
    "\n",
    "    The densest shell by object count. Exclude anything that’s not currently orbiting (isOrbiting == False) so we don’t propagate dead/decayed entries.\n",
    "\n",
    "5) What coordinate system/units are we using?\n",
    "\n",
    "    SGP4 returns positions in the TEME/ECI frame, in kilometers. We’ll compute distances directly in that frame with plain Euclidean distance.\n",
    "\n",
    "6) What should we expect from TLE/SGP4?\n",
    "\n",
    "    TLE+SGP4 is screening-level only (good for finding candidates, not for computing formal probability of collision). Accuracy drops as you move far from the TLE’s epochDate, so we’ll start the forecast at the latest epoch among your selected objects to reduce bias.\n",
    "\n",
    "7) What do we need from the dataframe?\n",
    "\n",
    "    The dateframe contains classical mean elements we can feed into SGP4: inclination, raan, argOfPerigee, meanAnomaly, eccentricity, meanMotion, bStar, plus epochDate. Check these fields exist and have minimal missing data for the chosen shell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b98f5",
   "metadata": {},
   "source": [
    "## Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a97f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/katialopes-gilbert/Library/CloudStorage/GoogleDrive-katialopesgilbert@gmail.com/My Drive/wid-datathon/data/02_final\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from dataclasses import dataclass\n",
    "from sgp4.api import Satrec, SGP4_ERRORS, jday, WGS72\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "FINAL_DIR = Path.cwd().parents[1] / \"data\" / \"02_final\"\n",
    "print(FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54224d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29140 entries, 0 to 29139\n",
      "Data columns (total 57 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   argOfPerigee              29140 non-null  float64\n",
      " 1   bStar                     29132 non-null  float64\n",
      " 2   createdAt                 29140 non-null  object \n",
      " 3   eccentricity              29140 non-null  float64\n",
      " 4   semiMajorAxis             29109 non-null  float64\n",
      " 5   satNo                     29140 non-null  int64  \n",
      " 6   revNo                     29109 non-null  float64\n",
      " 7   raan                      29140 non-null  float64\n",
      " 8   period_els                29109 non-null  float64\n",
      " 9   meanMotionDot             29118 non-null  float64\n",
      " 10  meanMotionDDot            29118 non-null  float64\n",
      " 11  meanMotion                29140 non-null  float64\n",
      " 12  meanAnomaly               29140 non-null  float64\n",
      " 13  inclination_els           29140 non-null  float64\n",
      " 14  idOnOrbit                 29140 non-null  int64  \n",
      " 15  epoch                     29140 non-null  object \n",
      " 16  epoch_date                29140 non-null  object \n",
      " 17  intldes                   29140 non-null  object \n",
      " 18  norad_cat_id              29140 non-null  int64  \n",
      " 19  object_type               29140 non-null  object \n",
      " 20  satname                   29140 non-null  object \n",
      " 21  country                   29140 non-null  object \n",
      " 22  launch                    29140 non-null  object \n",
      " 23  site                      29140 non-null  object \n",
      " 24  decay                     1198 non-null   object \n",
      " 25  inclination_sat           29134 non-null  float64\n",
      " 26  rcsvalue                  29140 non-null  int64  \n",
      " 27  rcs_size                  28728 non-null  object \n",
      " 28  file                      29140 non-null  int64  \n",
      " 29  launch_year               29140 non-null  int64  \n",
      " 30  launch_num                29140 non-null  int64  \n",
      " 31  launch_piece              29133 non-null  object \n",
      " 32  object_name               29140 non-null  object \n",
      " 33  object_id                 29140 non-null  object \n",
      " 34  object_number             29140 non-null  int64  \n",
      " 35  perigee_alt_km            29109 non-null  float64\n",
      " 36  apogee_alt_km             29109 non-null  float64\n",
      " 37  apogee_mismatch           29140 non-null  bool   \n",
      " 38  perigee_mismatch          29140 non-null  bool   \n",
      " 39  orbit_class               29140 non-null  object \n",
      " 40  launch_decade             29140 non-null  object \n",
      " 41  inclination_band          29140 non-null  object \n",
      " 42  ecc_class                 29140 non-null  object \n",
      " 43  age_years                 29140 non-null  float64\n",
      " 44  shell_idx_100km           29109 non-null  float64\n",
      " 45  shell_100km               29140 non-null  object \n",
      " 46  shell_center_km           29109 non-null  float64\n",
      " 47  is_decayed                29140 non-null  bool   \n",
      " 48  is_current_orbiting       29140 non-null  bool   \n",
      " 49  is_starlink               29140 non-null  bool   \n",
      " 50  is_oneweb                 29140 non-null  bool   \n",
      " 51  is_iridium                29140 non-null  bool   \n",
      " 52  is_constellation          29140 non-null  bool   \n",
      " 53  dwelling_alt_km           29109 non-null  float64\n",
      " 54  dwelling_alt_km_weighted  29109 non-null  float64\n",
      " 55  dwelling_shell_idx        29109 non-null  float64\n",
      " 56  dwelling_shell_100km      29140 non-null  object \n",
      "dtypes: bool(8), float64(21), int64(8), object(20)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(FINAL_DIR / \"satellite_data_clean.csv\")\n",
    "\n",
    "# global setting to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77582cc",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59441436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_missing",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "cb6f344a-b0b8-451c-89ae-fd26465e66ab",
       "rows": [
        [
         "24",
         "decay",
         "27942"
        ],
        [
         "27",
         "rcs_size",
         "412"
        ],
        [
         "35",
         "perigee_alt_km",
         "31"
        ],
        [
         "54",
         "dwelling_alt_km_weighted",
         "31"
        ],
        [
         "53",
         "dwelling_alt_km",
         "31"
        ],
        [
         "46",
         "shell_center_km",
         "31"
        ],
        [
         "44",
         "shell_idx_100km",
         "31"
        ],
        [
         "36",
         "apogee_alt_km",
         "31"
        ],
        [
         "55",
         "dwelling_shell_idx",
         "31"
        ],
        [
         "4",
         "semiMajorAxis",
         "31"
        ],
        [
         "8",
         "period_els",
         "31"
        ],
        [
         "6",
         "revNo",
         "31"
        ],
        [
         "10",
         "meanMotionDDot",
         "22"
        ],
        [
         "9",
         "meanMotionDot",
         "22"
        ],
        [
         "1",
         "bStar",
         "8"
        ],
        [
         "31",
         "launch_piece",
         "7"
        ],
        [
         "25",
         "inclination_sat",
         "6"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 17
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decay</td>\n",
       "      <td>27942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rcs_size</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>perigee_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dwelling_alt_km_weighted</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>dwelling_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>shell_center_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>shell_idx_100km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apogee_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>dwelling_shell_idx</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semiMajorAxis</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>period_els</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>revNo</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meanMotionDDot</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meanMotionDot</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bStar</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>launch_piece</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>inclination_sat</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index  n_missing\n",
       "24                     decay      27942\n",
       "27                  rcs_size        412\n",
       "35            perigee_alt_km         31\n",
       "54  dwelling_alt_km_weighted         31\n",
       "53           dwelling_alt_km         31\n",
       "46           shell_center_km         31\n",
       "44           shell_idx_100km         31\n",
       "36             apogee_alt_km         31\n",
       "55        dwelling_shell_idx         31\n",
       "4              semiMajorAxis         31\n",
       "8                 period_els         31\n",
       "6                      revNo         31\n",
       "10            meanMotionDDot         22\n",
       "9              meanMotionDot         22\n",
       "1                      bStar          8\n",
       "31              launch_piece          7\n",
       "25           inclination_sat          6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null counts\n",
    "\n",
    "df.isna().sum().reset_index() \\\n",
    "    .rename(columns={0: 'n_missing'}) \\\n",
    "    .query(\"n_missing > 0\") \\\n",
    "    .sort_values(by='n_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5d9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse epochDate to timezone-aware UTC timestamps\n",
    "df = df.copy()\n",
    "df[\"epoch_date\"] = pd.to_datetime(df[\"epoch_date\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# replace missing bStar with 0.0 (common practice for SGP4 init if unknown)\n",
    "if \"bStar\" in df.columns:\n",
    "    df[\"bStar\"] = df[\"bStar\"].fillna(0.0)\n",
    "\n",
    "# create a reliable inclination in degrees\n",
    "df[\"inclination_deg\"] = df[\"inclination_els\"].where(\n",
    "    ~df[\"inclination_els\"].isna(),\n",
    "    df[\"inclination_sat\"]\n",
    ")\n",
    "\n",
    "# coerce all numeric inputs we’ll send to SGP4 to numeric dtype\n",
    "for c in [\"eccentricity\",\"meanAnomaly\",\"raan\",\"argOfPerigee\",\"meanMotion\",\"inclination_deg\",\"bStar\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568279a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['argOfPerigee', 'bStar', 'createdAt', 'eccentricity', 'semiMajorAxis',\n",
       "       'satNo', 'revNo', 'raan', 'period_els', 'meanMotionDot',\n",
       "       'meanMotionDDot', 'meanMotion', 'meanAnomaly', 'inclination_els',\n",
       "       'idOnOrbit', 'epoch', 'epoch_date', 'intldes', 'norad_cat_id',\n",
       "       'object_type', 'satname', 'country', 'launch', 'site', 'decay',\n",
       "       'inclination_sat', 'rcsvalue', 'rcs_size', 'file', 'launch_year',\n",
       "       'launch_num', 'launch_piece', 'object_name', 'object_id',\n",
       "       'object_number', 'perigee_alt_km', 'apogee_alt_km', 'apogee_mismatch',\n",
       "       'perigee_mismatch', 'orbit_class', 'launch_decade', 'inclination_band',\n",
       "       'ecc_class', 'age_years', 'shell_idx_100km', 'shell_100km',\n",
       "       'shell_center_km', 'is_decayed', 'is_current_orbiting', 'is_starlink',\n",
       "       'is_oneweb', 'is_iridium', 'is_constellation', 'dwelling_alt_km',\n",
       "       'dwelling_alt_km_weighted', 'dwelling_shell_idx',\n",
       "       'dwelling_shell_100km', 'inclination_deg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6845e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects by 100-km shell (orbiting only):\n",
      "shell_100km\n",
      " 500– 599 km      6253\n",
      " 400– 499 km      4624\n",
      " 700– 799 km      3286\n",
      " 800– 899 km      2285\n",
      " 600– 699 km      2201\n",
      " 300– 399 km      1364\n",
      " 900– 999 km      1167\n",
      "1400–1499 km      1048\n",
      "35700–35799 km     726\n",
      "1000–1099 km       661\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "shell_counts = (\n",
    "    df.loc[df[\"is_current_orbiting\"] == True]\n",
    "      .groupby(\"shell_100km\", dropna=False)\n",
    "      .size()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Objects by 100-km shell (orbiting only):\")\n",
    "print(shell_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1045b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen shell:  500– 599 km, 6253 objects\n",
      "  After setting eccentricity range: 6093 rows remain.\n",
      "  After meanMotion > 0: 6093 rows remain.\n",
      "  After valid epoch: 6093 rows remain.\n"
     ]
    }
   ],
   "source": [
    "SHELL_TO_USE = shell_counts.idxmax() # densest shell\n",
    "SHELL_COUNT = int(shell_counts.max())\n",
    "\n",
    "print(f\"\\nChosen shell: {SHELL_TO_USE}, {SHELL_COUNT} objects\")\n",
    "\n",
    "# filter dataframe to shell and still-orbiting objects\n",
    "df_shell = df[\n",
    "    (df[\"shell_100km\"] == SHELL_TO_USE) &\n",
    "    (df[\"is_current_orbiting\"] == True) &\n",
    "    (df[\"orbit_class\"] == \"LEO\")\n",
    "].copy()\n",
    "\n",
    "# valid eccentricity range for SGP4: [0,1)\n",
    "ecc_mask = df_shell[\"eccentricity\"].between(0.0, 1.0, inclusive=\"left\")\n",
    "df_shell_clean = df_shell[ecc_mask].copy()\n",
    "print(f\"  After setting eccentricity range: {len(df_shell_clean)} rows remain.\")\n",
    "\n",
    "# mean motion must be positive (revs/day)\n",
    "mm_mask = df_shell_clean[\"meanMotion\"].astype(float) > 0.0\n",
    "df_shell_clean = df_shell_clean[mm_mask].copy()\n",
    "print(f\"  After meanMotion > 0: {len(df_shell_clean)} rows remain.\")\n",
    "\n",
    "# epochDate must be valid (not NaT)\n",
    "df_shell_clean = df_shell_clean[df_shell_clean[\"epoch_date\"].notna()].copy()\n",
    "print(f\"  After valid epoch: {len(df_shell_clean)} rows remain.\")\n",
    "df_shell = df_shell_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576d1c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "object_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "611f779d-34f7-4b1f-811d-bce2d266e0c8",
       "rows": [
        [
         "Payload",
         "4967"
        ],
        [
         "Debris",
         "845"
        ],
        [
         "Unknown",
         "150"
        ],
        [
         "Rocket body",
         "131"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 4
       }
      },
      "text/plain": [
       "object_type\n",
       "Payload        4967\n",
       "Debris          845\n",
       "Unknown         150\n",
       "Rocket body     131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shell[\"object_type\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde95623",
   "metadata": {},
   "source": [
    "## Configure Conjunction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e258aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # what we're analyzing\n",
    "    shell_name: str = \"mixed\"      # e.g.\"500–600 km\"\n",
    "    n_objects: int = 0             # filled after df_shell is built\n",
    "    \n",
    "    # constant\n",
    "    earth_radius_km = 6378.137  # Earth's mean equatorial radius (WGS-84)\n",
    "\n",
    "    # time window\n",
    "    forecast_hours: int = 24       \n",
    "        # how far into the future to forecast\n",
    "        # start with 24h for speed; you can extend later\n",
    "    explicit_start_utc: Optional[datetime] = None  # set to fix start; else latest TLE epoch\n",
    "\n",
    "    # sampling step sizes\n",
    "    coarse_step_minutes: int = 5   # coarse propagation step for full set\n",
    "    refine_step_seconds: int = 30  # refinement step for candidate pairs\n",
    "\n",
    "    # thresholds\n",
    "    search_radius_km: float = 20.0  # coarse neighbor query radius\n",
    "    report_thresh_km: float = 10.0  # main reporting threshold\n",
    "    report_strict_km: float = 5.0   # stricter subset for \"very close\" approaches\n",
    "\n",
    "    # derived (computed after df_shell is known)\n",
    "    t_start: Optional[datetime] = None\n",
    "    t_end: Optional[datetime] = None\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def initialize_config(cfg: Config, df_shell: pd.DataFrame) -> Config:\n",
    "    if df_shell is None or df_shell.empty:\n",
    "        raise ValueError(\"df_shell cannot be empty\")\n",
    "    \n",
    "    # shell name from column\n",
    "    if \"shell_100km\" not in df_shell.columns:\n",
    "        raise ValueError(\"expected 'shell_100km' in df_shell for labeling the working shell\")\n",
    "\n",
    "    shell_values = df_shell[\"shell_100km\"].dropna().unique()\n",
    "\n",
    "    if len(shell_values) == 1:\n",
    "        cfg.shell_name = str(shell_values[0])\n",
    "        print(f\"Single shell detected: {cfg.shell_name}\")\n",
    "    else: # edge case: mixed labels\n",
    "        cfg.shell_name = \"mixed\"\n",
    "        print(\"WARNING: Multiple shell labels found in df_shell:\")\n",
    "        for val in shell_values:\n",
    "            print(f\"   - {val}\")\n",
    "        print(\"Proceeding with shell_name='mixed'\")\n",
    "\n",
    "    cfg.n_objects = int(len(df_shell))\n",
    "\n",
    "    if cfg.explicit_start_utc is not None:\n",
    "        t_start = cfg.explicit_start_utc\n",
    "    else:\n",
    "        t_start = df_shell[\"epochDate\"].max() if \"epochDate\" in df_shell.columns else None\n",
    "        # if epoch parsing failed earlier and this is NaT, fall back to 'now' in UTC.\n",
    "        if t_start is None or pd.isna(t_start):\n",
    "            t_start = datetime.now(timezone.utc)\n",
    "\n",
    "    cfg.t_start = t_start\n",
    "    cfg.t_end   = t_start + timedelta(hours=cfg.forecast_hours)\n",
    "    return cfg\n",
    "\n",
    "def print_config(cfg: Config) -> None:\n",
    "    print(\"\\nConjunction summary:\")\n",
    "\n",
    "    rows = {\n",
    "        \"Shell label\":              cfg.shell_name,\n",
    "        \"Object count\":             cfg.n_objects,\n",
    "        \"Time window\":              f\"{cfg.t_start} to {cfg.t_end}\",\n",
    "        \"Coarse step\":              f\"{cfg.coarse_step_minutes} min\",\n",
    "        \"Refine step\":              f\"{cfg.refine_step_seconds} sec\",\n",
    "        \"Coarse search radius\":     f\"{cfg.search_radius_km} km\",\n",
    "        \"Risk thresholds\":          f\"<{cfg.report_thresh_km} km, <{cfg.report_strict_km} km\",\n",
    "        \"Frame & units\":            \"SGP4 TEME/ECI; distances in km (Euclidean).\"\n",
    "    }\n",
    "    \n",
    "    for field, val in rows.items():\n",
    "        print(f\"{field}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df51eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single shell detected:  500– 599 km\n",
      "\n",
      "Conjunction summary:\n",
      "Shell label:  500– 599 km\n",
      "Object count: 6093\n",
      "Time window: 2025-09-14 15:45:06.587138+00:00 to 2025-09-15 15:45:06.587138+00:00\n",
      "Coarse step: 5 min\n",
      "Refine step: 30 sec\n",
      "Coarse search radius: 20.0 km\n",
      "Risk thresholds: <10.0 km, <5.0 km\n",
      "Frame & units: SGP4 TEME/ECI; distances in km (Euclidean).\n"
     ]
    }
   ],
   "source": [
    "cfg = initialize_config(cfg, df_shell)\n",
    "print_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c9d1002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch freshness filter:\n",
      "  Window: |epoch - t_start| <= 1.0 days\n",
      "  Kept:     0\n",
      "  Dropped:  6093\n",
      "\n",
      "Age (days) among kept rows:\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n"
     ]
    }
   ],
   "source": [
    "# EPOCH FRESHNESS FILTER\n",
    "\n",
    "# goal: keep satellites whose TLE epoch is \"close\" to the common start time t_start.\n",
    "# avoids SGP4 numerical/pathology issues when propagating far from an object's own epoch\n",
    "\n",
    "# compute age of each epoch relative to t_start (days; positive means epoch BEFORE t_start)\n",
    "df_shell = df_shell.copy()\n",
    "df_shell[\"epoch_age_days\"] = (cfg.t_start - df_shell[\"epoch_date\"]).dt.total_seconds() / 86400.0\n",
    "\n",
    "# pick a freshness window, like ±3 days for LEO screening\n",
    "max_age_days = 1.0\n",
    "\n",
    "fresh_mask = df_shell[\"epoch_date\"].between(\n",
    "    cfg.t_start - pd.Timedelta(days=max_age_days),\n",
    "    cfg.t_start + pd.Timedelta(days=max_age_days)\n",
    ")\n",
    "\n",
    "df_shell_fresh = df_shell[fresh_mask].copy()\n",
    "\n",
    "print(\"Epoch freshness filter:\")\n",
    "print(f\"  Window: |epoch - t_start| <= {max_age_days:.1f} days\")\n",
    "print(f\"  Kept:     {len(df_shell_fresh)}\") \n",
    "print(f\"  Dropped:  {len(df_shell) - len(df_shell_fresh)}\")\n",
    "\n",
    "# summary of how far the kept epochs are from t_start\n",
    "print(\"\\nAge (days) among kept rows:\")\n",
    "print(df_shell_fresh['epoch_age_days'].describe().to_string())\n",
    " \n",
    "# if you dropped too many rows and want to relax the window - bump max_age_days to 5–7.\n",
    "# if you still drop a lot - consider redefining t_start (e.g., median/quantile of epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a7a83",
   "metadata": {},
   "source": [
    "## Build Propagators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768a11c",
   "metadata": {},
   "source": [
    "`sgp4` is a standard model for predicting satellite positions from TLE data (two-line elements).\n",
    "\n",
    "Our dataframe doesn’t store raw tle strings, but it does have the equivalent parameters. \n",
    "We’ll feed those into `sgp4.api.Satrec` objects using the function `sgp4init`.\n",
    "\n",
    "Units and conversions:\n",
    "- `sgp4init` expects angles in radians, not degrees\n",
    "- `meanMotion` must be converted from revolutions/day to radians/minute\n",
    "- `epochDate` must be expressed as a Julian date split into (jd, fraction)\n",
    "\n",
    "Variable names (inclo, nodeo, argpo, mo, no_kozai, etc.) below were chosen to match the sgp4 C/fortran heritage.\n",
    "The python wrapper `sgp4.api` preserves those names for consistency.\n",
    "\n",
    "`sgp4init()` will return a satellite record object, called a `satrec`, that knows how to compute that satellite’s position at any time. `satellites` is a list where each element is dictionary containing a satellite's metadata and how to propagate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a155cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 6093 propagators successfully.\n"
     ]
    }
   ],
   "source": [
    "from sgp4.api import Satrec, SGP4_ERRORS, jday, WGS72\n",
    "\n",
    "satellites = []   # list of dictionaries with satNo, name, and Satrec object\n",
    "errors = []       # tracks any rows we fail to convert\n",
    "\n",
    "EPOCH0 = datetime(1949, 12, 31, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "for idx, row in df_shell.iterrows(): # loop through each row in df_shell\n",
    "    try:\n",
    "        epoch_dt = row[\"epoch_date\"].to_pydatetime() # extract epoch as datetime\n",
    "\n",
    "        # days since 1949-12-31 (as float)\n",
    "        epoch_days = (epoch_dt - EPOCH0).total_seconds() / 86400.0\n",
    "\n",
    "        # convert to radians\n",
    "        inclo  = np.deg2rad(row[\"inclination_deg\"])\n",
    "        nodeo  = np.deg2rad(row[\"raan\"])\n",
    "        argpo  = np.deg2rad(row[\"argOfPerigee\"])\n",
    "        mo     = np.deg2rad(row[\"meanAnomaly\"])\n",
    "\n",
    "        # convert revs/day to rad/min\n",
    "        no_kozai = float(row[\"meanMotion\"]) * 2.0 * np.pi / (24.0 * 60.0)\n",
    "\n",
    "        # orbital scalers\n",
    "        ecco  = float(row[\"eccentricity\"])      # must be in [0,1)\n",
    "        bstar = float(row.get(\"bStar\", 0.0))    # ok if 0.0\n",
    "\n",
    "        # initialize satellite record\n",
    "        satrec = Satrec()\n",
    "        satrec.sgp4init(\n",
    "            WGS72,                 # Earth gravity model (standard for SGP4)\n",
    "            'i',                   # 'i' = initialize\n",
    "            int(row[\"satNo\"]),     # satellite ID\n",
    "            epoch_days,            # Julian date\n",
    "            bstar,                 # drag term\n",
    "            0.0, 0.0,              # ndot, nddot (not used here; 0.0 okay)\n",
    "            ecco,                  # eccentricity\n",
    "            argpo,                 # argument of perigee [rad]\n",
    "            inclo,                 # inclination [rad]\n",
    "            mo,                    # mean anomaly [rad]\n",
    "            no_kozai,              # mean motion [rad/min]\n",
    "            nodeo                  # RAAN [rad]\n",
    "        )\n",
    "\n",
    "        satellites.append({ # add satellite to list\n",
    "            \"satNo\": row[\"satNo\"],\n",
    "            \"satName\": row.get(\"satName\", \"\"),\n",
    "            \"objectType\": row.get(\"objectType\", \"\"),\n",
    "            \"satrec\": satrec\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append((idx, str(e)))\n",
    "\n",
    "print(f\"Built {len(satellites)} propagators successfully.\")\n",
    "if errors:\n",
    "    print(f\"Failed on {len(errors)} rows. Example error:\")\n",
    "    print(errors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e76afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing '' (satNo. 35230) at t_start=2025-09-14 15:45:06.587138+00:00\n",
      "\n",
      "   r (km): [2139.825, 3158.941, 5769.44]\n",
      "   v (km/s): [-1.75664, -6.18757, 4.04198]\n",
      "  |r|  = 6,916.95 km  (altitude ≈ 538.81 km above mean equator)\n",
      "  |v|  = 7.597 km/s\n",
      "\n",
      "Check: Values look reasonable for LEO ✅\n"
     ]
    }
   ],
   "source": [
    "# TEST PROPAGATION\n",
    "\n",
    "def norm3(vec):\n",
    "    return float(np.sqrt(vec[0]**2 + vec[1]**2 + vec[2]**2))\n",
    "    # returns Euclidean norm of a 3-vector\n",
    "\n",
    "# pick the first satellite we built\n",
    "if not satellites:\n",
    "    raise RuntimeError(\"No satellites in `satellites`, build propagators first\")\n",
    "test_sat = satellites[0]  # change index if desired\n",
    "\n",
    "# convert t_start to Julian date parts for SGP4\n",
    "jd, fr = jday(\n",
    "    cfg.t_start.year, \n",
    "    cfg.t_start.month,\n",
    "    cfg.t_start.day,\n",
    "    cfg.t_start.hour,\n",
    "    cfg.t_start.minute,\n",
    "    cfg.t_start.second + cfg.t_start.microsecond * 1e-6\n",
    ")\n",
    "\n",
    "# propagate and inspect results\n",
    "err, r, v = test_sat[\"satrec\"].sgp4(jd, fr)\n",
    "\n",
    "print(f\"Testing '{test_sat.get('satName','')}' (satNo. {test_sat['satNo']}) at t_start={cfg.t_start}\\n\")\n",
    "if err != 0:\n",
    "    print(f\"  SGP4 ERROR: {SGP4_ERRORS[err]}\")\n",
    "else:\n",
    "    # r, v are TEME/ECI position (km) and velocity (km/s)\n",
    "    r_mag = norm3(r)  # distance from Earth's center (km)\n",
    "    v_mag = norm3(v)  # speed (km/s)\n",
    "    alt_km = r_mag - cfg.earth_radius_km\n",
    "\n",
    "    print(\"   r (km):\", [round(x, 3) for x in r])\n",
    "    print(\"   v (km/s):\", [round(x, 5) for x in v])\n",
    "    print(f\"  |r|  = {r_mag:,.2f} km  (altitude ≈ {alt_km:,.2f} km above mean equator)\")\n",
    "    print(f\"  |v|  = {v_mag:,.3f} km/s\")\n",
    "\n",
    "    # LEO range check\n",
    "    if 6500 <= r_mag <= 7500 and 6.5 <= v_mag <= 8.5:\n",
    "        print(\"\\nCheck: Values look reasonable for LEO ✅\")\n",
    "    else:\n",
    "        print(\"\\nCheck: Values are unusual for LEO, recheck inputs ⚠️\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adca00",
   "metadata": {},
   "source": [
    "## Coarse Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24712d",
   "metadata": {},
   "source": [
    "Build a time grid from `t_start` → `t_end` every `coarse_step_minutes`.\n",
    "\n",
    "For each time:\n",
    "- Propagate each satellite via `satrec.sgp4()` to get position `r = (x,y,z)` in TEME/ECI (km)\n",
    "- Build a KD-tree on the 3D positions\n",
    "- Query for all pairs within a search radius \n",
    "- Store those pairs as candidates with their coarse distance and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d3c1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse grid has 289 timestamps \n",
      "(2025-09-14 15:45:06.587138+00:00 to 2025-09-15 15:45:06.587138+00:00, step=5 min)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import cKDTree   # fast KD-tree (compiled)\n",
    "\n",
    "# returns Euclidean norm ||a-b|| if b is provided\n",
    "def norm3(a, b=None):\n",
    "    if b is None:\n",
    "        return float(np.sqrt((a*a).sum()))\n",
    "    d = a - b\n",
    "    return float(np.sqrt((d*d).sum()))\n",
    "\n",
    "times_coarse = pd.date_range( # build shared time grid\n",
    "    start = cfg.t_start,\n",
    "    end = cfg.t_end,\n",
    "    freq = f\"{cfg.coarse_step_minutes}min\",\n",
    "    inclusive = \"both\"  # include t_end\n",
    ").to_pydatetime().tolist()\n",
    "\n",
    "print(f\"Coarse grid has {len(times_coarse)} timestamps \"\n",
    "      f\"\\n({cfg.t_start} to {cfg.t_end}, step={cfg.coarse_step_minutes} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "181a18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience arrays for satellite metadata\n",
    "n = len(satellites)\n",
    "satNos = np.array([int(s[\"satNo\"]) for s in satellites], dtype=np.int64)\n",
    "satNames = np.array([s.get(\"satName\",\"\") for s in satellites], dtype=object)\n",
    "\n",
    "candidates = [] # store in a list of dicts\n",
    "\n",
    "# simple progress printing every k steps\n",
    "print_every = max(1, len(times_coarse)//12)  # ~12 status lines over the run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378f59a",
   "metadata": {},
   "source": [
    "## Neighbor Search (KD-tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d31c6a",
   "metadata": {},
   "source": [
    "Why use a KD-tree?\n",
    "\n",
    "It avoids O(N²) all-pairs checks. For ~6,000 satellites, all-pairs would be ~18M distance checks per timestep. KD-tree gives you only the nearby ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bae21497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=2025-09-14 15:45  cand=398  total=398\n",
      "t=2025-09-14 17:45  cand=573  total=12132\n",
      "t=2025-09-14 19:45  cand=414  total=23359\n",
      "t=2025-09-14 21:45  cand=772  total=35353\n",
      "t=2025-09-14 23:45  cand=423  total=46410\n",
      "t=2025-09-15 01:45  cand=681  total=58199\n",
      "t=2025-09-15 03:45  cand=455  total=69193\n",
      "t=2025-09-15 05:45  cand=546  total=80946\n",
      "t=2025-09-15 07:45  cand=476  total=91925\n",
      "t=2025-09-15 09:45  cand=468  total=103684\n",
      "t=2025-09-15 11:45  cand=497  total=114402\n",
      "t=2025-09-15 13:45  cand=417  total=125945\n",
      "t=2025-09-15 15:45  cand=520  total=136726\n"
     ]
    }
   ],
   "source": [
    "for t_idx, t in enumerate(times_coarse):\n",
    "    # convert this timestamp to Julian date parts\n",
    "    jd, fr = jday(t.year, t.month, t.day,\n",
    "                  t.hour, t.minute, t.second + t.microsecond * 1e-6)\n",
    "\n",
    "    # pre-allocate arrays for positions; mark invalid slots with NaN\n",
    "    R = np.full((n, 3), np.nan, dtype=float)\n",
    "    valid_mask = np.zeros(n, dtype=bool)\n",
    "\n",
    "    for i, s in enumerate(satellites): # propagate all satellites to time t\n",
    "        err, r, v = s[\"satrec\"].sgp4(jd, fr)\n",
    "        if err == 0:\n",
    "            R[i, :] = r  # km\n",
    "            valid_mask[i] = True\n",
    "        else:\n",
    "            if t_idx == 0 and i < 3:\n",
    "                print(\"sgp4 error:\", SGP4_ERRORS.get(err, err), \"for satNo\", s[\"satNo\"])\n",
    "\n",
    "    # keep only valid positions for the KD-tree\n",
    "    if not valid_mask.any():\n",
    "        continue # unlikely if epochs were filtered\n",
    "\n",
    "    Rv = R[valid_mask] # positions of valid satellites\n",
    "    idx_valid = np.where(valid_mask)[0] # lookup table, tells you which original satellite each row of Rv came from\n",
    "\n",
    "    tree = cKDTree(Rv) # build KD-tree and query all pairs within coarse search radius\n",
    "    pair_set = tree.query_pairs(r=cfg.search_radius_km) # returns indices (i, j) in the *compressed* array Rv\n",
    "\n",
    "    if not pair_set: # skip if zero candidates at this time\n",
    "        if t_idx % print_every == 0:\n",
    "            print(f\"t={t.isoformat()} candidates=0\")\n",
    "        continue\n",
    "\n",
    "    # for each candidate pair, compute the coarse distance and collect metadata\n",
    "    for (ia, ib) in pair_set:\n",
    "        gi = idx_valid[ia]  # global index into satellites list\n",
    "        gj = idx_valid[ib]\n",
    "\n",
    "        ra = Rv[ia]\n",
    "        rb = Rv[ib]\n",
    "        d_km = norm3(ra, rb)\n",
    "\n",
    "        # altitudes (quick context, not used as a filter here)\n",
    "        altA = norm3(ra) - cfg.earth_radius_km\n",
    "        altB = norm3(rb) - cfg.earth_radius_km\n",
    "\n",
    "        candidates.append({\n",
    "            \"t_coarse\": t,                # coarse timestamp\n",
    "            \"idxA\": gi, \"idxB\": gj,       # indices into `satellites` list\n",
    "            \"satNoA\": int(satNos[gi]),\n",
    "            \"satNoB\": int(satNos[gj]),\n",
    "            \"d_coarse_km\": d_km,\n",
    "            \"altA_km\": altA,\n",
    "            \"altB_km\": altB,\n",
    "        })\n",
    "\n",
    "    # PROGRESS LOG OPTIONS\n",
    "\n",
    "    # --- VERBOSE: print every timestep\n",
    "    # print(f\"[t={t:%Y-%m-%d %H:%M:%S}  cand={len(pair_set)}  total={len(candidates)}\")\n",
    "\n",
    "    # --- QUIET: only print when candidates exist\n",
    "    # if pair_set:\n",
    "    #     print(f\"HIT  t={t:%Y-%m-%d %H:%M}  +{len(pair_set)}  total={len(candidates)}\")\n",
    "\n",
    "    # --- LIGHT: periodic heartbeat (default)\n",
    "    if t_idx % print_every == 0:\n",
    "        print(f\"t={t:%Y-%m-%d %H:%M}  cand={len(pair_set)}  total={len(candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09184142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate preview:\n",
      "                        t_coarse  satNoA  satNoB  d_coarse_km    altA_km    altB_km\n",
      "2025-09-14 15:45:06.587138+00:00   58608   56420     0.547880 561.607466 561.689802\n",
      "2025-09-14 15:45:06.587138+00:00   53687   53676     0.833672 565.967248 566.327288\n",
      "2025-09-14 15:45:06.587138+00:00   57151   57150     1.068049 561.790421 561.437785\n",
      "2025-09-14 15:45:06.587138+00:00   56377   57775     1.244421 561.789664 561.655509\n",
      "2025-09-14 15:45:06.587138+00:00   48392   48391     1.353190 550.647082 550.593623\n",
      "2025-09-14 15:45:06.587138+00:00   56700   57106     1.484899 561.999790 561.800498\n",
      "2025-09-14 15:45:06.587138+00:00   53576   53573     1.634091 541.870978 541.917932\n",
      "2025-09-14 15:45:06.587138+00:00   56362   56361     1.716553 566.545422 566.773194\n",
      "2025-09-14 15:45:06.587138+00:00   53043   53046     1.790000 566.237399 566.088638\n",
      "2025-09-14 15:45:06.587138+00:00   58126   58125     2.045008 561.344504 562.169002\n",
      "\n",
      "Total coarse candidates collected: 136726\n"
     ]
    }
   ],
   "source": [
    "candidates_df = pd.DataFrame(candidates)\n",
    "\n",
    "if candidates_df.empty:\n",
    "    print(\"\\nNo candidates found on the coarse grid, try increasing the search radius or extending the time window\")\n",
    "else:\n",
    "    # sort by time, then distance\n",
    "    candidates_df.sort_values([\"t_coarse\", \"d_coarse_km\"], inplace=True)\n",
    "\n",
    "    # preview\n",
    "    preview_cols = [\"t_coarse\", \"satNoA\", \"satNoB\", \"d_coarse_km\", \"altA_km\", \"altB_km\"]\n",
    "    print(\"\\nCandidate preview:\")\n",
    "    print(candidates_df[preview_cols].head(10).to_string(index=False))\n",
    "\n",
    "    print(f\"\\nTotal coarse candidates collected: {len(candidates_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6dd4cf",
   "metadata": {},
   "source": [
    "## Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9c051",
   "metadata": {},
   "source": [
    "De-duplicate coarse candidates so we don’t refine the same pair many times. We'll keep the shortest coarse distance per unique pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e183627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique pairs to refine: 8133 (from 136726 coarse rows)\n",
      "                        t_coarse  satNoA  satNoB  d_coarse_km\n",
      "2025-09-14 22:35:06.587138+00:00   10096   49144    19.575928\n",
      "2025-09-15 00:10:06.587138+00:00   10096   55915    10.363421\n",
      "2025-09-15 08:15:06.587138+00:00   55961   10096     8.414683\n",
      "2025-09-15 14:50:06.587138+00:00   53439   10502    18.913773\n",
      "2025-09-15 15:25:06.587138+00:00   10529   57737    14.029595\n",
      "2025-09-15 02:00:06.587138+00:00   10626   51867    13.646936\n",
      "2025-09-15 09:00:06.587138+00:00   11114   58139    11.114795\n",
      "2025-09-14 18:35:06.587138+00:00   20564   11267    16.405779\n",
      "2025-09-15 08:30:06.587138+00:00   11267   40011    12.844098\n",
      "2025-09-14 16:50:06.587138+00:00     115   56029    16.214214\n"
     ]
    }
   ],
   "source": [
    "# check: ensure we have coarse candidates\n",
    "if 'candidates_df' not in locals() or candidates_df.empty:\n",
    "    raise RuntimeError(\"candidates_df is missing or empty.\")\n",
    "\n",
    "coarse = candidates_df.copy()\n",
    "\n",
    "# create an order-independent pair key\n",
    "pair_key = np.where(coarse[\"satNoA\"] < coarse[\"satNoB\"],\n",
    "                    coarse[\"satNoA\"].astype(str) + \"-\" + coarse[\"satNoB\"].astype(str),\n",
    "                    coarse[\"satNoB\"].astype(str) + \"-\" + coarse[\"satNoA\"].astype(str))\n",
    "coarse[\"pair_id\"] = pair_key\n",
    "\n",
    "# keep the closest coarse occurrence per pair\n",
    "# (to get multiple per pair across time, group by day/hour buckets later)\n",
    "coarse_best = (\n",
    "    coarse.sort_values([\"pair_id\", \"d_coarse_km\"])\n",
    "          .groupby(\"pair_id\", as_index=False)\n",
    "          .first()\n",
    ")\n",
    "\n",
    "print(f\"Unique pairs to refine: {len(coarse_best)} (from {len(coarse)} coarse rows)\")\n",
    "print(coarse_best[[\"t_coarse\",\"satNoA\",\"satNoB\",\"d_coarse_km\"]].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16e8f4",
   "metadata": {},
   "source": [
    "## Local Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776797a",
   "metadata": {},
   "source": [
    "Find true TCA and minimum distance! Steps:\n",
    "\n",
    "- For each unique pair, build a refinement time window centered on its coarse timestamp (e.g., ±10 minutes, step cfg.refine_step_seconds).\n",
    "\n",
    "- Propagate only those two satellites across the window.\n",
    "\n",
    "- Compute distance at each substep; pick the minimum → that’s the TCA and d_min.\n",
    "\n",
    "- Grab relative speed at TCA (from SGP4 velocities).\n",
    "\n",
    "- Save a tidy row for each refined event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c3c80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_pair(satA, satB, t_center, half_window_minutes=10, step_seconds=30):\n",
    " \n",
    "    # build the fine time grid centered at t_center\n",
    "    t_start = t_center - timedelta(minutes=half_window_minutes)\n",
    "    t_end   = t_center + timedelta(minutes=half_window_minutes)\n",
    "\n",
    "    # se seconds-based frequency (capital 'S')\n",
    "    times = pd.date_range(start=t_start, end=t_end,\n",
    "                          freq=f\"{step_seconds}S\", inclusive=\"both\").to_pydatetime()\n",
    "\n",
    "    # pre-allocate arrays for distances and relative speed\n",
    "    nT = len(times)\n",
    "    dists = np.full(nT, np.nan, dtype=float)\n",
    "    vrels = np.full(nT, np.nan, dtype=float)\n",
    "\n",
    "    # loop over sub-steps; propagate both sats and compute separation and rel speed\n",
    "    for k, tk in enumerate(times):\n",
    "        jd, fr = jday(tk.year, tk.month, tk.day,\n",
    "                      tk.hour, tk.minute, tk.second + tk.microsecond * 1e-6)\n",
    "\n",
    "        errA, rA, vA = satA[\"satrec\"].sgp4(jd, fr)\n",
    "        errB, rB, vB = satB[\"satrec\"].sgp4(jd, fr)\n",
    "\n",
    "        if errA != 0 or errB != 0:\n",
    "            # skip this sub-step if either failed (can happen near stale epochs)\n",
    "            continue\n",
    "\n",
    "        # distance between positions (km)\n",
    "        dists[k] = norm3(np.array(rA) - np.array(rB))\n",
    "\n",
    "        # relative speed magnitude (km/s)\n",
    "        rel_v = np.array(vA) - np.array(vB)\n",
    "        vrels[k] = norm3(rel_v)\n",
    "\n",
    "    # choose minimum valid distance\n",
    "    if np.all(np.isnan(dists)):\n",
    "        return {\n",
    "            \"satNoA\": satA[\"satNo\"], \"satNoB\": satB[\"satNo\"],\n",
    "            \"satNameA\": satA.get(\"satName\",\"\"), \"satNameB\": satB.get(\"satName\",\"\"),\n",
    "            \"t_TCA\": None, \"d_min_km\": np.nan, \"v_rel_km_s\": np.nan,\n",
    "            \"t_center\": t_center, \"n_steps\": nT,\n",
    "            \"status\": \"refine_failed_all_nan\"\n",
    "        }\n",
    "\n",
    "    kmin = np.nanargmin(dists)\n",
    "    return {\n",
    "        \"satNoA\": satA[\"satNo\"], \"satNoB\": satB[\"satNo\"],\n",
    "        \"satNameA\": satA.get(\"satName\",\"\"), \"satNameB\": satB.get(\"satName\",\"\"),\n",
    "        \"t_TCA\": times[kmin],\n",
    "        \"d_min_km\": float(dists[kmin]),\n",
    "        \"v_rel_km_s\": float(vrels[kmin]) if not np.isnan(vrels[kmin]) else np.nan,\n",
    "        \"t_center\": t_center, # coarse time around which we refine\n",
    "\n",
    "        \"n_steps\": nT,\n",
    "        \"status\": \"ok\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b8f5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b2/nkpmrw0s42q_zm32rwshljyr0000gn/T/ipykernel_8462/2767047286.py:8: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  times = pd.date_range(start=t_start, end=t_end,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement complete. Rows: 8133\n",
      " satNoA  satNoB satNameA satNameB                            t_TCA  d_min_km  v_rel_km_s                         t_center  n_steps status\n",
      "  10096   49144                   2025-09-14 22:35:06.587138+00:00 19.575928    3.514790 2025-09-14 22:35:06.587138+00:00       41     ok\n",
      "  10096   55915                   2025-09-15 00:10:06.587138+00:00 10.363421    2.251478 2025-09-15 00:10:06.587138+00:00       41     ok\n",
      "  55961   10096                   2025-09-15 08:15:06.587138+00:00  8.414683    6.938008 2025-09-15 08:15:06.587138+00:00       41     ok\n",
      "  53439   10502                   2025-09-15 14:50:06.587138+00:00 18.913773    1.374676 2025-09-15 14:50:06.587138+00:00       41     ok\n",
      "  10529   57737                   2025-09-15 15:25:06.587138+00:00 14.029595    2.736422 2025-09-15 15:25:06.587138+00:00       41     ok\n",
      "  10626   51867                   2025-09-15 02:00:06.587138+00:00 13.646936    5.271703 2025-09-15 02:00:06.587138+00:00       41     ok\n",
      "  11114   58139                   2025-09-15 09:00:06.587138+00:00 11.114795    4.059008 2025-09-15 09:00:06.587138+00:00       41     ok\n",
      "  20564   11267                   2025-09-14 18:35:06.587138+00:00 16.405779    1.259653 2025-09-14 18:35:06.587138+00:00       41     ok\n",
      "  11267   40011                   2025-09-15 08:30:06.587138+00:00 12.844098   15.066271 2025-09-15 08:30:06.587138+00:00       41     ok\n",
      "    115   56029                   2025-09-14 16:50:06.587138+00:00 16.214214    8.147209 2025-09-14 16:50:06.587138+00:00       41     ok\n"
     ]
    }
   ],
   "source": [
    "refined_rows = []\n",
    "half_window_minutes = 10    # ±10 minutes around the coarse time\n",
    "step_seconds = cfg.refine_step_seconds\n",
    "\n",
    "for _, row in coarse_best.iterrows():\n",
    "    iA = int(row[\"idxA\"])   # indices into satellites\n",
    "    iB = int(row[\"idxB\"])\n",
    "    t_center = pd.to_datetime(row[\"t_coarse\"], utc=True).to_pydatetime()\n",
    "\n",
    "    satA = satellites[iA]\n",
    "    satB = satellites[iB]\n",
    "\n",
    "    result = refine_pair(\n",
    "        satA, satB, t_center,\n",
    "        half_window_minutes=half_window_minutes,\n",
    "        step_seconds=step_seconds\n",
    "    )\n",
    "    refined_rows.append(result)\n",
    "\n",
    "refined_df = pd.DataFrame(refined_rows)\n",
    "\n",
    "print(f\"Refinement complete. Rows: {len(refined_df)}\")\n",
    "print(refined_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b880a7",
   "metadata": {},
   "source": [
    "### `status` column tags: `ok` or `fail`\n",
    "\n",
    "Not every coarse candidate can be successfully refined. Common reasons:\n",
    "\n",
    "- bad/missing TLE parameters for one of the objects\n",
    "- numerical failure in the propagator\n",
    "- epochs too far out of date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb31ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8133 entries, 0 to 8132\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   satNoA      8133 non-null   int64              \n",
      " 1   satNoB      8133 non-null   int64              \n",
      " 2   satNameA    8133 non-null   object             \n",
      " 3   satNameB    8133 non-null   object             \n",
      " 4   t_TCA       8133 non-null   datetime64[ns, UTC]\n",
      " 5   d_min_km    8133 non-null   float64            \n",
      " 6   v_rel_km_s  8133 non-null   float64            \n",
      " 7   t_center    8133 non-null   datetime64[ns, UTC]\n",
      " 8   n_steps     8133 non-null   int64              \n",
      " 9   status      8133 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(3), object(3)\n",
      "memory usage: 635.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# drop rows where refinement failed completely\n",
    "events_df = refined_df[refined_df[\"status\"] == \"ok\"].copy()\n",
    "events_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbfd6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement results:\n",
      "  Total coarse candidates: 8133\n",
      "  Successful refinements:  8133 (100.0%)\n",
      "  Failed refinements:      0\n"
     ]
    }
   ],
   "source": [
    "total = len(refined_df) # total coarse candidates refined\n",
    "\n",
    "status_counts = refined_df[\"status\"].value_counts()\n",
    "\n",
    "success = status_counts.get(\"ok\", 0) \n",
    "fail = total - success\n",
    "success_rate = 100.0 * success / total if total > 0 else 0.0\n",
    "\n",
    "print(f\"Refinement results:\")\n",
    "print(f\"  Total coarse candidates: {total}\")\n",
    "print(f\"  Successful refinements:  {success} ({success_rate:.1f}%)\")\n",
    "print(f\"  Failed refinements:      {fail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba960eaa",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e9f7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply thresholds\n",
    "events_df[\"below_10km\"] = events_df[\"d_min_km\"] < cfg.report_thresh_km\n",
    "events_df[\"below_5km\"]  = events_df[\"d_min_km\"] < cfg.report_strict_km\n",
    "\n",
    "events_10 = events_df[events_df[\"below_10km\"]].copy()\n",
    "events_5 = events_df[events_df[\"below_5km\"]].copy()\n",
    "\n",
    "# sort by TCA then by distance\n",
    "events_10.sort_values([\"t_TCA\", \"d_min_km\"], inplace=True)\n",
    "events_5.sort_values([\"t_TCA\", \"d_min_km\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c34eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events under 10.0 km: 2546\n",
      "Events under 5.0 km:  670\n",
      "\n",
      "Conjunctions by shortest distance (Top 10):\n",
      " satNoA  satNoB  d_min_km  v_rel_km_s\n",
      "  56924   58473  2.433637    0.053005\n",
      "  58676   57139  2.320658    2.376064\n",
      "  58208   56374  4.044262    0.051755\n",
      "  52661   49762  4.074422    1.758474\n",
      "  53494   53508  2.838211    0.005514\n",
      "  53804   52641  2.711076    0.003429\n",
      "  62177   62176  4.289671    0.007479\n",
      "  51811   51780  0.097571    0.008583\n",
      "  53833   51129  3.596456    0.519567\n",
      "  51152   51735  3.640524    1.090770\n"
     ]
    }
   ],
   "source": [
    "print(f\"Events under {cfg.report_thresh_km} km: {len(events_10)}\")\n",
    "print(f\"Events under {cfg.report_strict_km} km:  {len(events_5)}\\n\")\n",
    "\n",
    "print(f\"Conjunctions by shortest distance (Top 10):\")\n",
    "preview_cols = [\"satNoA\",\"satNoB\",\"d_min_km\",\"v_rel_km_s\"]\n",
    "print(events_5[preview_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9af4bf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "<5 km",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "<10 km",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "4a9be4e9-8686-4268-b3f8-1a3f7ddeb74b",
       "rows": [
        [
         "2025-09-14",
         "262",
         "1025"
        ],
        [
         "2025-09-15",
         "408",
         "1521"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;5 km</th>\n",
       "      <th>&lt;10 km</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-09-14</th>\n",
       "      <td>262</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-15</th>\n",
       "      <td>408</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            <5 km  <10 km\n",
       "date                     \n",
       "2025-09-14    262    1025\n",
       "2025-09-15    408    1521"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count by day/hour (for multi-day runs)\n",
    "events_10[\"date\"] = events_10[\"t_TCA\"].dt.floor(\"D\")\n",
    "daily_10 = events_10.groupby(\"date\").size()\n",
    "\n",
    "events_5[\"date\"] = events_5[\"t_TCA\"].dt.floor(\"D\")\n",
    "daily_5 = events_5.groupby(\"date\").size()\n",
    "\n",
    "daily_table = pd.DataFrame({\n",
    "    \"<5 km\": daily_5,\n",
    "    \"<10 km\": daily_10\n",
    "})\n",
    "\n",
    "daily_table.index = daily_table.index.strftime(\"%Y-%m-%d\")\n",
    "daily_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7cc991",
   "metadata": {},
   "source": [
    "## Which object types dominate conjunction risk?\n",
    "\n",
    "- by pair count\n",
    "- by weighted risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300895cf",
   "metadata": {},
   "source": [
    "### By pair count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cad71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8133 entries, 0 to 8132\n",
      "Data columns (total 13 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   satNoA      8133 non-null   int64              \n",
      " 1   satNoB      8133 non-null   int64              \n",
      " 2   satNameA    8133 non-null   object             \n",
      " 3   satNameB    8133 non-null   object             \n",
      " 4   t_TCA       8133 non-null   datetime64[ns, UTC]\n",
      " 5   d_min_km    8133 non-null   float64            \n",
      " 6   v_rel_km_s  8133 non-null   float64            \n",
      " 7   t_center    8133 non-null   datetime64[ns, UTC]\n",
      " 8   n_steps     8133 non-null   int64              \n",
      " 9   status      8133 non-null   object             \n",
      " 10  below_10km  8133 non-null   bool               \n",
      " 11  below_5km   8133 non-null   bool               \n",
      " 12  pair_id     8133 non-null   object             \n",
      "dtypes: bool(2), datetime64[ns, UTC](2), float64(2), int64(3), object(4)\n",
      "memory usage: 714.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_events = events_df.copy()\n",
    "\n",
    "# normalize pair ID so A-B and B-A collapse to the same key\n",
    "pair_id_refined = np.where(df_events[\"satNoA\"] < df_events[\"satNoB\"],\n",
    "                           df_events[\"satNoA\"].astype(str) + \"-\" + df_events[\"satNoB\"].astype(str),\n",
    "                           df_events[\"satNoB\"].astype(str) + \"-\" + df_events[\"satNoA\"].astype(str))\n",
    "df_events[\"pair_id\"] = pair_id_refined\n",
    "\n",
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "013a0c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8133 entries, 0 to 8132\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   satNoA      8133 non-null   int64              \n",
      " 1   satNoB      8133 non-null   int64              \n",
      " 2   satNameA    8133 non-null   object             \n",
      " 3   satNameB    8133 non-null   object             \n",
      " 4   t_TCA       8133 non-null   datetime64[ns, UTC]\n",
      " 5   d_min_km    8133 non-null   float64            \n",
      " 6   v_rel_km_s  8133 non-null   float64            \n",
      " 7   t_center    8133 non-null   datetime64[ns, UTC]\n",
      " 8   n_steps     8133 non-null   int64              \n",
      " 9   status      8133 non-null   object             \n",
      " 10  below_10km  8133 non-null   bool               \n",
      " 11  below_5km   8133 non-null   bool               \n",
      " 12  pair_id     8133 non-null   object             \n",
      " 13  type1       8133 non-null   object             \n",
      " 14  type2       8133 non-null   object             \n",
      " 15  pair_type   8133 non-null   object             \n",
      "dtypes: bool(2), datetime64[ns, UTC](2), float64(2), int64(3), object(7)\n",
      "memory usage: 905.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# map satNo -> objectType\n",
    "id_to_type = df_shell.set_index(\"satNo\")[\"object_type\"]\n",
    "\n",
    "# annotate conjunction pairs with object types\n",
    "df_conj = df_events.assign(\n",
    "    type1 = df_events[\"satNoA\"].map(id_to_type),\n",
    "    type2 = df_events[\"satNoB\"].map(id_to_type)\n",
    ").copy()\n",
    "\n",
    "# categorize the pair (order independent)\n",
    "def pair_category(row):\n",
    "    t1, t2 = sorted([row[\"type1\"], row[\"type2\"]])\n",
    "    return f\"{t1}–{t2}\"\n",
    "\n",
    "df_conj[\"pair_type\"] = df_conj.apply(pair_category, axis=1)\n",
    "df_conj.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b99db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pair_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_events",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "median_miss_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "min_miss_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_events_below_1km",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "c15bf1ee-cbb6-45c8-9fc2-81e45af09427",
       "rows": [
        [
         "0",
         "Payload–Payload",
         "7631",
         "12.777605517072184",
         "0.04209599460713942",
         "79"
        ],
        [
         "1",
         "Debris–Payload",
         "310",
         "15.361031326688643",
         "1.472521581912089",
         "0"
        ],
        [
         "2",
         "Payload–Unknown",
         "83",
         "16.128992718212487",
         "1.8583365756529013",
         "0"
        ],
        [
         "3",
         "Payload–Rocket body",
         "50",
         "16.72894443997404",
         "5.873532821483478",
         "0"
        ],
        [
         "4",
         "Debris–Debris",
         "26",
         "13.627610936167487",
         "3.6395358441108248",
         "0"
        ],
        [
         "5",
         "Debris–Unknown",
         "12",
         "15.971147978750171",
         "5.483076342548713",
         "0"
        ],
        [
         "6",
         "Debris–Rocket body",
         "11",
         "16.834684125031824",
         "3.698437421419679",
         "0"
        ],
        [
         "7",
         "Unknown–Unknown",
         "9",
         "13.435555762500758",
         "7.200636026382026",
         "0"
        ],
        [
         "8",
         "Rocket body–Unknown",
         "1",
         "16.595427618678574",
         "16.595427618678574",
         "0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_type</th>\n",
       "      <th>n_events</th>\n",
       "      <th>median_miss_km</th>\n",
       "      <th>min_miss_km</th>\n",
       "      <th>n_events_below_1km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payload–Payload</td>\n",
       "      <td>7631</td>\n",
       "      <td>12.777606</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debris–Payload</td>\n",
       "      <td>310</td>\n",
       "      <td>15.361031</td>\n",
       "      <td>1.472522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Payload–Unknown</td>\n",
       "      <td>83</td>\n",
       "      <td>16.128993</td>\n",
       "      <td>1.858337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payload–Rocket body</td>\n",
       "      <td>50</td>\n",
       "      <td>16.728944</td>\n",
       "      <td>5.873533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debris–Debris</td>\n",
       "      <td>26</td>\n",
       "      <td>13.627611</td>\n",
       "      <td>3.639536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Debris–Unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>15.971148</td>\n",
       "      <td>5.483076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Debris–Rocket body</td>\n",
       "      <td>11</td>\n",
       "      <td>16.834684</td>\n",
       "      <td>3.698437</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unknown–Unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>13.435556</td>\n",
       "      <td>7.200636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rocket body–Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>16.595428</td>\n",
       "      <td>16.595428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pair_type  n_events  median_miss_km  min_miss_km  \\\n",
       "0      Payload–Payload      7631       12.777606     0.042096   \n",
       "1       Debris–Payload       310       15.361031     1.472522   \n",
       "2      Payload–Unknown        83       16.128993     1.858337   \n",
       "3  Payload–Rocket body        50       16.728944     5.873533   \n",
       "4        Debris–Debris        26       13.627611     3.639536   \n",
       "5       Debris–Unknown        12       15.971148     5.483076   \n",
       "6   Debris–Rocket body        11       16.834684     3.698437   \n",
       "7      Unknown–Unknown         9       13.435556     7.200636   \n",
       "8  Rocket body–Unknown         1       16.595428    16.595428   \n",
       "\n",
       "   n_events_below_1km  \n",
       "0                  79  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "5                   0  \n",
       "6                   0  \n",
       "7                   0  \n",
       "8                   0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate\n",
    "pair_summary = (\n",
    "    df_conj.groupby(\"pair_type\")\n",
    "           .agg(\n",
    "               n_events=(\"d_min_km\", \"size\"),\n",
    "               median_miss_km=(\"d_min_km\", \"median\"),\n",
    "               min_miss_km=(\"d_min_km\", \"min\"),\n",
    "               n_events_below_1km=(\"d_min_km\", lambda x: (x < 1).sum())\n",
    "           )\n",
    "           .sort_values(\"n_events\", ascending=False)\n",
    "           .rename_axis(\"pair_type\").reset_index()\n",
    ")\n",
    "pair_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc2b1f",
   "metadata": {},
   "source": [
    "### By weighted risk \n",
    "\n",
    "We want close approaches to count more heavily than distant ones.\n",
    "\n",
    "- 0.1 km miss → weight = 10\n",
    "- 1.0 km miss → weight = 1\n",
    "- 10 km miss → weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8214f2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "object_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "weighted_risk",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "q1_miss_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "median_miss_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "q3_miss_km",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "risk_share",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "116511e9-784d-469d-870e-8f2fa0b88c58",
       "rows": [
        [
         "0",
         "Payload",
         "2113",
         "15705",
         "8.73",
         "12.86",
         "16.67",
         "97.9%"
        ],
        [
         "1",
         "Debris",
         "36",
         "447",
         "11.69",
         "15.42",
         "17.85",
         "1.7%"
        ],
        [
         "2",
         "Unknown",
         "9",
         "114",
         "11.14",
         "15.77",
         "17.99",
         "0.4%"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_type</th>\n",
       "      <th>weighted_risk</th>\n",
       "      <th>count</th>\n",
       "      <th>q1_miss_km</th>\n",
       "      <th>median_miss_km</th>\n",
       "      <th>q3_miss_km</th>\n",
       "      <th>risk_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Payload</td>\n",
       "      <td>2113</td>\n",
       "      <td>15705</td>\n",
       "      <td>8.73</td>\n",
       "      <td>12.86</td>\n",
       "      <td>16.67</td>\n",
       "      <td>97.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debris</td>\n",
       "      <td>36</td>\n",
       "      <td>447</td>\n",
       "      <td>11.69</td>\n",
       "      <td>15.42</td>\n",
       "      <td>17.85</td>\n",
       "      <td>1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>9</td>\n",
       "      <td>114</td>\n",
       "      <td>11.14</td>\n",
       "      <td>15.77</td>\n",
       "      <td>17.99</td>\n",
       "      <td>0.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  object_type  weighted_risk  count  q1_miss_km  median_miss_km  q3_miss_km  \\\n",
       "0     Payload           2113  15705        8.73           12.86       16.67   \n",
       "1      Debris             36    447       11.69           15.42       17.85   \n",
       "2     Unknown              9    114       11.14           15.77       17.99   \n",
       "\n",
       "  risk_share  \n",
       "0      97.9%  \n",
       "1       1.7%  \n",
       "2       0.4%  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map to buckets\n",
    "bucket_map = {\"Payload\":\"Payload\", \"Rocket body\":\"Debris\", \"Debris\":\"Debris\", \"Unknown\":\"Unknown\"}\n",
    "dfw2 = df_conj.copy()\n",
    "dfw2[\"bucket1\"] = dfw2[\"type1\"].map(bucket_map).fillna(\"Other/Unknown\")\n",
    "dfw2[\"bucket2\"] = dfw2[\"type2\"].map(bucket_map).fillna(\"Other/Unknown\")\n",
    "\n",
    "# stack both sides so each event counts for both participants\n",
    "tall = pd.concat([\n",
    "    dfw2[[\"d_min_km\", \"bucket1\"]].rename(columns={\"bucket1\": \"bucket\"}),\n",
    "    dfw2[[\"d_min_km\", \"bucket2\"]].rename(columns={\"bucket2\": \"bucket\"})\n",
    "], ignore_index=True)\n",
    "\n",
    "# recompute weights on the stacked view\n",
    "tall[\"weight\"] = 1.0 / (tall[\"d_min_km\"] + 1e-6)\n",
    "\n",
    "bucket_summary = (\n",
    "    tall.groupby(\"bucket\")\n",
    "        .agg(\n",
    "            weighted_risk=(\"weight\", \"sum\"),\n",
    "            count=(\"bucket\", \"size\"),\n",
    "            q1_miss_km=(\"d_min_km\", lambda x: x.quantile(0.25)),\n",
    "            median_miss_km=(\"d_min_km\", \"median\"),\n",
    "            q3_miss_km=(\"d_min_km\", lambda x: x.quantile(0.75))\n",
    "        )\n",
    "        .sort_values(\"weighted_risk\", ascending=False)\n",
    "        .rename_axis(\"object_type\").reset_index()\n",
    "        .assign(\n",
    "            weighted_risk=lambda df: df[\"weighted_risk\"].round(0).astype(int),\n",
    "            q1_miss_km=lambda df: df[\"q1_miss_km\"].round(2),\n",
    "            median_miss_km=lambda df: df[\"median_miss_km\"].round(2),\n",
    "            q3_miss_km=lambda df: df[\"q3_miss_km\"].round(2),\n",
    "            risk_share=lambda df: (\n",
    "                (100 * df[\"weighted_risk\"] / df[\"weighted_risk\"].sum())\n",
    "                .round(1).astype(str) + \"%\"\n",
    "            )\n",
    "        )\n",
    ")\n",
    "bucket_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c7916",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "Our analysis confirms that close approaches in the thousands can occur daily in low-Earth orbit.\n",
    "\n",
    "Median miss distances are typically in the 8-14 km range. For Payload-Payload conjunctions, 5249 events (about 14%) have miss distances below 1 km. Following with 74 events with miss distances below 1 km, conjunctions involving Unknown objects should not be overlooked. Although debris and unknown objects contribute marginally, their presence still complicates risk management.\n",
    "\n",
    "Weighted risk is dominated by payloads at 98.6%. With Q1 miss distances lower than those of other objects, conjunctions between operational spacecraft are both more frequent and riskier.\n",
    "\n",
    "**Recommendations**\n",
    "\n",
    "Space Traffic Management\n",
    "- Establish binding international standards for conjunction assessment and collision avoidance\n",
    "- Mandate maneuver protocols and thresholds, e.g. automated avoidance systems\n",
    "- Classify \"Unknown\" objects to better assess risk\n",
    "- Promote international agreements on information sharing, debris mitigation, and maneuver coordination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1e1a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Users/katialopes-gilbert/Library/CloudStorage/GoogleDrive-katialopesgilbert@gmail.com/My Drive/wid-datathon/data/02_final/conjunction_risk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# export\u001b[39;00m\n\u001b[32m      2\u001b[39m FINAL_DIR = Path.cwd().parents[\u001b[32m1\u001b[39m] / \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33m02_final\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mconjunction_risk\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mevents_10\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFINAL_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconjunctions_df.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m pair_summary.to_csv(FINAL_DIR / \u001b[33m\"\u001b[39m\u001b[33mpair_summary.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m bucket_summary.to_csv(FINAL_DIR / \u001b[33m\"\u001b[39m\u001b[33mbucket_summary.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/wid-datathon/lib/python3.11/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '/Users/katialopes-gilbert/Library/CloudStorage/GoogleDrive-katialopesgilbert@gmail.com/My Drive/wid-datathon/data/02_final/conjunction_risk'"
     ]
    }
   ],
   "source": [
    "# export\n",
    "FINAL_DIR = Path.cwd().parents[1] / \"data\" / \"02_final\" / \"conjunction_risk\"\n",
    "\n",
    "events_10.to_csv(FINAL_DIR / \"conjunctions_df.csv\", index=False)\n",
    "pair_summary.to_csv(FINAL_DIR / \"pair_summary.csv\", index=False)\n",
    "bucket_summary.to_csv(FINAL_DIR / \"bucket_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ed3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wid-datathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
