{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79d3999",
   "metadata": {},
   "source": [
    "# Conjunction Risk Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8ecfb",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "From 2020 to 2024, satellites operating in Earth orbit grew from 3,371 to 11,539. In this year alone, more than 1,200 satellites were launched into orbit from January to April. SpaceX led with 573 Starlink satellites during the Q1 of 2025.\n",
    "\n",
    "Our space environment is becoming increasingly crowded as the number of satellites and large constellations like Starlink continue to grow. In addition to these new launches, inactive satellites in Low Earth Orbit (LEO) can remain in orbit for years to centuries. \n",
    "\n",
    "Each additional satellite increases conjunction frequency and thus creates more chances for collision. When two satellites collide, they can produce thousands of pieces of debris and trigger cascading collision events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e47c0a",
   "metadata": {},
   "source": [
    "Sources: \n",
    "- [Satellite Industry Association Releases the 28th Annual State of the Satellite Industry Report](https://sia.org/historic-number-of-launches-powers-commercial-satellite-industry-growth-satellite-industry-association-releases-the-28th-annual-state-of-the-satellite-industry-report/)\n",
    "- [Orbital debris and the market for satellites](https://www.sciencedirect.com/science/article/pii/S0921800923000940)\n",
    "- [Modeling Orbital Decay of Low-Earth Orbit Satellites due to Atmospheric Drag](https://arxiv.org/pdf/2508.19549)\n",
    "- [NASA Spacecraft Conjunction Assessment and Collision Avoidance Best Practices Handbook](https://ntrs.nasa.gov/api/citations/20230002470/downloads/CA_Handbook_CM%20Version%202-24-23.docx.pdf?utm_source=chatgpt.com)\n",
    "- [Satellite orbital conjunction reports assessing threatening encounters in space (SOCRATES)](https://conference.sdo.esoc.esa.int/proceedings/sdc4/paper/2/SDC4-paper2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fd18a",
   "metadata": {},
   "source": [
    "## Goal: Forecast Conjunction Risk\n",
    "\n",
    "Steps (EDIT)\n",
    "1. Predict orbits into future\n",
    "3. Determine conjunction frequency\n",
    "4. Find objects with repeating conjunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347690a1",
   "metadata": {},
   "source": [
    "## Key Terms and Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e751bc",
   "metadata": {},
   "source": [
    "### 1. What is a shell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bdc8e",
   "metadata": {},
   "source": [
    "A shell is band of altitudes where satellites are placed. It is not as single orbit but a \"layer\" above Earth where satellites can exist with different inclinations and longitudes.\n",
    "\n",
    "**Risks of different shells:**\n",
    "\n",
    "- Shells below 500 km are less crowded, but satellites decay faster due to atmospheric drag.\n",
    "\n",
    "- Shells between 500–600 km very popular because they balance longer lifetime with lower launch cost. However, conjunctions risks are higher since the space is more crowded. Lifetime could be years to decades, e.g. a dead satellite at 550 km might remain in orbit for 10-25 years before atmospheric reentry.\n",
    "\n",
    "- There is less drag in shells above 800 km, so satellites can stay for decades to centuries. This is bad for long-term sustainability since debris also lingers forever.\n",
    "\n",
    "- Objects in the geostationary orbit shell (~36,000 km) remain essentially forever as there is meaningful drag at all. Satellites must be moved to a \"graveyard orbit\" when retired.\n",
    "\n",
    "**Lifetimes** \n",
    "\n",
    "Consider a typical satellite-sized object that is about 100–1,000 kg with moderate drag area.\n",
    "\n",
    "Below are its orbital lifetime estimates by altitude:\n",
    "\n",
    "- 300-400 km:           ~0-2 years before atmospheric reentry\n",
    "- 500-600 km:           ~5–30 years\n",
    "- 700-800 km:           ~80–400 years\n",
    "- 900-1,000 km:         ~500–1,500 years\n",
    "- 1,200 km and above:   2,000+ years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743244a",
   "metadata": {},
   "source": [
    "### 2. Space Object Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da744769",
   "metadata": {},
   "source": [
    "|*Object Type*|*Description*|*Importance in Conjunction Risk Analysis*|\n",
    "| - | - | - |\n",
    "|**Payload**|Operational or defunct satellites|Valuable, often maneuverable, critical to protect|\n",
    "|**Rocket body**|Spent propulsion units to deploy satellites into orbit, i.e. launch vehicle stages|Large, non-maneuverable, collision threat|\n",
    "|**Debris**|Fragments from explosions, collisions, breakups|Numerous and unpredictable|\n",
    "|**Unknown**|Identified but unclassified objects|Complicates modeling with uncertainty, could be a hazard or payload|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db38f4",
   "metadata": {},
   "source": [
    "Why are rocket bodies catalogued differently than standard debris?\n",
    "\n",
    "* From [Space Track Documentation](https://www.space-track.org/documentation#legend): \n",
    "\n",
    "    They can have mechanisms or fuel on board that can affect the orbital behavior of the rocket body even after long periods of time. Rocket bodies are also constructed to endure high temperatures and stresses associated with launch, so they have a greater probability of surviving reentry and require closer attention than most debris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f93c87",
   "metadata": {},
   "source": [
    "### 3. Conjunction vs. Collision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53fa73f",
   "metadata": {},
   "source": [
    "Conjunction: A close approach between two objects in space, defined by a threshold distance. \n",
    "\n",
    "Collision: An event where wo objects hit each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ca853",
   "metadata": {},
   "source": [
    "## Historical Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f1075",
   "metadata": {},
   "source": [
    "### 2009 - The First Satellite Collision\n",
    "\n",
    "The [collision of Iridium 33 and Cosmos 2251](https://ntrs.nasa.gov/api/citations/20100002023/downloads/20100002023.pdf) produced more than 1800 pieces of debris that were larger than 10 cm. Some of which will remain in orbit through 2100.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b98f5",
   "metadata": {},
   "source": [
    "## Import Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a97f4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ash\\Desktop\\wid-datathon\\data\\02_final\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\", force=True)  # headless, stable backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "FINAL_DIR = Path.cwd().parents[1] / \"data\" / \"02_final\"\n",
    "print(FINAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54224d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29140 entries, 0 to 29139\n",
      "Data columns (total 57 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   argOfPerigee              29140 non-null  float64\n",
      " 1   bStar                     29132 non-null  float64\n",
      " 2   createdAt                 29140 non-null  object \n",
      " 3   eccentricity              29140 non-null  float64\n",
      " 4   semiMajorAxis             29109 non-null  float64\n",
      " 5   satNo                     29140 non-null  int64  \n",
      " 6   revNo                     29109 non-null  float64\n",
      " 7   raan                      29140 non-null  float64\n",
      " 8   period_els                29109 non-null  float64\n",
      " 9   meanMotionDot             29118 non-null  float64\n",
      " 10  meanMotionDDot            29118 non-null  float64\n",
      " 11  meanMotion                29140 non-null  float64\n",
      " 12  meanAnomaly               29140 non-null  float64\n",
      " 13  inclination_els           29140 non-null  float64\n",
      " 14  idOnOrbit                 29140 non-null  int64  \n",
      " 15  epoch                     29140 non-null  object \n",
      " 16  epochDate                 29140 non-null  object \n",
      " 17  intldes                   29140 non-null  object \n",
      " 18  noradCatId                29140 non-null  int64  \n",
      " 19  objectType                29140 non-null  object \n",
      " 20  satName                   29140 non-null  object \n",
      " 21  country                   29140 non-null  object \n",
      " 22  launch                    29140 non-null  object \n",
      " 23  site                      29140 non-null  object \n",
      " 24  decay                     1198 non-null   object \n",
      " 25  inclination_sat           29134 non-null  float64\n",
      " 26  rcsValue                  29140 non-null  int64  \n",
      " 27  rcsSize                   28728 non-null  object \n",
      " 28  file                      29140 non-null  int64  \n",
      " 29  launchYear                29140 non-null  int64  \n",
      " 30  launchNum                 29140 non-null  int64  \n",
      " 31  launchPiece               29133 non-null  object \n",
      " 32  objectName                29140 non-null  object \n",
      " 33  objectId                  29140 non-null  object \n",
      " 34  objectNumber              29140 non-null  int64  \n",
      " 35  perigee_alt_km            29109 non-null  float64\n",
      " 36  apogee_alt_km             29109 non-null  float64\n",
      " 37  apogee_mismatch           29140 non-null  bool   \n",
      " 38  perigee_mismatch          29140 non-null  bool   \n",
      " 39  orbitClass                29140 non-null  object \n",
      " 40  launchDecade              29140 non-null  object \n",
      " 41  inclinationBand           29140 non-null  object \n",
      " 42  eccClass                  29140 non-null  object \n",
      " 43  ageInYears                29140 non-null  float64\n",
      " 44  shell_idx_100km           29109 non-null  float64\n",
      " 45  shell_100km               29140 non-null  object \n",
      " 46  shell_center_km           29109 non-null  float64\n",
      " 47  isDecayed                 29140 non-null  bool   \n",
      " 48  isOrbiting                29140 non-null  bool   \n",
      " 49  isStarlink                29140 non-null  bool   \n",
      " 50  isOneweb                  29140 non-null  bool   \n",
      " 51  isIridium                 29140 non-null  bool   \n",
      " 52  isConstellation           29140 non-null  bool   \n",
      " 53  dwelling_alt_km           29109 non-null  float64\n",
      " 54  dwelling_alt_km_weighted  29109 non-null  float64\n",
      " 55  dwelling_shell_idx        29109 non-null  float64\n",
      " 56  dwelling_shell_100km      29140 non-null  object \n",
      "dtypes: bool(8), float64(21), int64(8), object(20)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(FINAL_DIR / \"satellite_data_clean.csv\")\n",
    "# shell_summary = pd.read_csv(FINAL_DIR / \"satellite_shell_summary.csv\")\n",
    "\n",
    "# global setting to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040166b0",
   "metadata": {},
   "source": [
    "## Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f1b479",
   "metadata": {},
   "source": [
    "1) What time horizon are we forecasting?\n",
    "    \n",
    "    Screen for close approaches over the next 24 hours.\n",
    "    This is long enough to see interesting traffic but short enough to run fast on a laptop with thousands of objects.\n",
    "    May extend to 48–72 hours later if it runs quickly.\n",
    "\n",
    "2) How fine is our sampling of time?\n",
    "\n",
    "    Propagate every 5 minutes at first (coarse pass).\n",
    "    For any potential close approach we find, we’ll re-check just those two satellites around that time at 30-second steps to refine the minimum distance.\n",
    "    This will keep runtime manageable and still finds the real minimum distance accurately.\n",
    "\n",
    "3) What counts as a “conjunction”?\n",
    "\n",
    "    Flag pairs that ever get within 10 km (and we’ll also count the stricter 5 km subset).\n",
    "    We’ll use an initial search radius of 20 km during the coarse pass to make sure we don’t miss events that dip below 10 km between 5-minute samples.\n",
    "\n",
    "4) Which objects are we analyzing?\n",
    "\n",
    "    The densest shell by object count. Exclude anything that’s not currently orbiting (isOrbiting == False) so we don’t propagate dead/decayed entries.\n",
    "\n",
    "5) What coordinate system/units are we using?\n",
    "\n",
    "    SGP4 returns positions in the TEME/ECI frame, in kilometers.\n",
    "    We’ll compute distances directly in that frame with plain Euclidean distance.\n",
    "\n",
    "6) What should we expect from TLE/SGP4?\n",
    "\n",
    "    TLE+SGP4 is screening-level only (good for finding candidates, not for computing formal probability of collision).\n",
    "    Accuracy drops as you move far from the TLE’s epochDate, so we’ll start the forecast at the latest epoch among your selected objects to reduce bias.\n",
    "\n",
    "7) What do we need from the dataframe?\n",
    "\n",
    "    The dateframe contains classical mean elements we can feed into SGP4:\n",
    "    inclination, raan, argOfPerigee, meanAnomaly, eccentricity, meanMotion, bStar, plus epochDate.\n",
    "    Check these fields exist and have minimal missing data for the chosen shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59441436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>n_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>decay</td>\n",
       "      <td>27942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rcsSize</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>perigee_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dwelling_alt_km_weighted</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>dwelling_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>shell_center_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>shell_idx_100km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apogee_alt_km</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>dwelling_shell_idx</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semiMajorAxis</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>period_els</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>revNo</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meanMotionDDot</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meanMotionDot</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bStar</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>launchPiece</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>inclination_sat</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       index  n_missing\n",
       "24                     decay      27942\n",
       "27                   rcsSize        412\n",
       "35            perigee_alt_km         31\n",
       "54  dwelling_alt_km_weighted         31\n",
       "53           dwelling_alt_km         31\n",
       "46           shell_center_km         31\n",
       "44           shell_idx_100km         31\n",
       "36             apogee_alt_km         31\n",
       "55        dwelling_shell_idx         31\n",
       "4              semiMajorAxis         31\n",
       "8                 period_els         31\n",
       "6                      revNo         31\n",
       "10            meanMotionDDot         22\n",
       "9              meanMotionDot         22\n",
       "1                      bStar          8\n",
       "31               launchPiece          7\n",
       "25           inclination_sat          6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null counts\n",
    "\n",
    "df.isna().sum().reset_index() \\\n",
    "    .rename(columns={0: 'n_missing'}) \\\n",
    "    .query(\"n_missing > 0\") \\\n",
    "    .sort_values(by='n_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5d9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# parse epochDate to timezone-aware UTC timestamps\n",
    "df = df.copy()\n",
    "df[\"epochDate\"] = pd.to_datetime(df[\"epochDate\"], utc=True, errors=\"coerce\")\n",
    "\n",
    "# replace missing bStar with 0.0 (common practice for SGP4 init if unknown)\n",
    "if \"bStar\" in df.columns:\n",
    "    df[\"bStar\"] = df[\"bStar\"].fillna(0.0)\n",
    "\n",
    "# create a reliable inclination in degrees\n",
    "df[\"inclination_deg\"] = df[\"inclination_els\"].where(\n",
    "    ~df[\"inclination_els\"].isna(),\n",
    "    df[\"inclination_sat\"]\n",
    ")\n",
    "\n",
    "# coerce all numeric inputs we’ll send to SGP4 to numeric dtype\n",
    "for c in [\"eccentricity\",\"meanAnomaly\",\"raan\",\"argOfPerigee\",\"meanMotion\",\"inclination_deg\",\"bStar\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6845e45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects by 100-km shell (orbiting only):\n",
      "shell_100km\n",
      " 500– 599 km      6253\n",
      " 400– 499 km      4624\n",
      " 700– 799 km      3286\n",
      " 800– 899 km      2285\n",
      " 600– 699 km      2201\n",
      " 300– 399 km      1364\n",
      " 900– 999 km      1167\n",
      "1400–1499 km      1048\n",
      "35700–35799 km     726\n",
      "1000–1099 km       661\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "shell_counts = (\n",
    "    df.loc[df[\"isOrbiting\"] == True]\n",
    "      .groupby(\"shell_100km\", dropna=False)\n",
    "      .size()\n",
    "      .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Objects by 100-km shell (orbiting only):\")\n",
    "print(shell_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1045b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chosen shell:  500– 599 km (objects: 6253)\n",
      "  After setting eccentricity range: 6093 rows remain.\n",
      "  After meanMotion > 0: 6093 rows remain.\n",
      "  After valid epoch: 6093 rows remain.\n"
     ]
    }
   ],
   "source": [
    "SHELL_TO_USE = shell_counts.idxmax() # densest shell\n",
    "SHELL_COUNT = int(shell_counts.max())\n",
    "\n",
    "print(f\"\\nChosen shell: {SHELL_TO_USE} (objects: {SHELL_COUNT})\")\n",
    "\n",
    "# filter dataframe to shell and still-orbiting objects\n",
    "df_shell = df[\n",
    "    (df[\"shell_100km\"] == SHELL_TO_USE) &\n",
    "    (df[\"isOrbiting\"] == True) &\n",
    "    (df[\"orbitClass\"] == \"LEO\")\n",
    "].copy()\n",
    "\n",
    "\n",
    "# valid eccentricity range for SGP4: [0,1)\n",
    "ecc_mask = df_shell[\"eccentricity\"].between(0.0, 1.0, inclusive=\"left\")\n",
    "df_shell_clean = df_shell[ecc_mask].copy()\n",
    "print(f\"  After setting eccentricity range: {len(df_shell_clean)} rows remain.\")\n",
    "\n",
    "# mean motion must be positive (revs/day)\n",
    "mm_mask = df_shell_clean[\"meanMotion\"].astype(float) > 0.0\n",
    "df_shell_clean = df_shell_clean[mm_mask].copy()\n",
    "print(f\"  After meanMotion > 0: {len(df_shell_clean)} rows remain.\")\n",
    "\n",
    "# epochDate must be valid (not NaT)\n",
    "df_shell_clean = df_shell_clean[df_shell_clean[\"epochDate\"].notna()].copy()\n",
    "print(f\"  After valid epoch: {len(df_shell_clean)} rows remain.\")\n",
    "df_shell = df_shell_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "576d1c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "objectType\n",
       "Payload        4967\n",
       "Debris          845\n",
       "Unknown         150\n",
       "Rocket body     131\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_shell[\"objectType\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde95623",
   "metadata": {},
   "source": [
    "## Configure Conjunction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e258aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # what we're analyzing\n",
    "    shell_name: str = \"mixed\"      # e.g.\"500–600 km\"\n",
    "    n_objects: int = 0             # filled after df_shell is built\n",
    "    \n",
    "    # constant\n",
    "    earth_radius_km = 6378.137  # Earth's mean equatorial radius (WGS-84)\n",
    "\n",
    "    # time window\n",
    "    forecast_hours: int = 24       \n",
    "        # how far into the future to forecast\n",
    "        # start with 24h for speed; you can extend later\n",
    "    explicit_start_utc: Optional[datetime] = None  # set to fix start; else latest TLE epoch\n",
    "\n",
    "    # sampling step sizes\n",
    "    coarse_step_minutes: int = 5   # coarse propagation step for full set\n",
    "    refine_step_seconds: int = 30  # refinement step for candidate pairs\n",
    "\n",
    "    # thresholds\n",
    "    search_radius_km: float = 20.0  # coarse neighbor query radius\n",
    "    report_thresh_km: float = 10.0  # main reporting threshold\n",
    "    report_strict_km: float = 5.0   # stricter subset for \"very close\" approaches\n",
    "\n",
    "    # derived (computed after df_shell is known)\n",
    "    t_start: Optional[datetime] = None\n",
    "    t_end: Optional[datetime] = None\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "def initialize_config(cfg: Config, df_shell: pd.DataFrame) -> Config:\n",
    "    if df_shell is None or df_shell.empty:\n",
    "        raise ValueError(\"df_shell cannot be empty\")\n",
    "    \n",
    "    # shell name from column\n",
    "    if \"shell_100km\" not in df_shell.columns:\n",
    "        raise ValueError(\"expected 'shell_100km' in df_shell for labeling the working shell\")\n",
    "\n",
    "    shell_values = df_shell[\"shell_100km\"].dropna().unique()\n",
    "\n",
    "    if len(shell_values) == 1:\n",
    "        cfg.shell_name = str(shell_values[0])\n",
    "        print(f\"Single shell detected: {cfg.shell_name}\")\n",
    "    else: # edge case: mixed labels\n",
    "        cfg.shell_name = \"mixed\"\n",
    "        print(\"WARNING: Multiple shell labels found in df_shell:\")\n",
    "        for val in shell_values:\n",
    "            print(f\"   - {val}\")\n",
    "        print(\"Proceeding with shell_name='mixed'\")\n",
    "\n",
    "    cfg.n_objects = int(len(df_shell))\n",
    "\n",
    "    if cfg.explicit_start_utc is not None:\n",
    "        t_start = cfg.explicit_start_utc\n",
    "    else:\n",
    "        t_start = df_shell[\"epochDate\"].max() if \"epochDate\" in df_shell.columns else None\n",
    "        # if epoch parsing failed earlier and this is NaT, fall back to 'now' in UTC.\n",
    "        if t_start is None or pd.isna(t_start):\n",
    "            t_start = datetime.now(timezone.utc)\n",
    "\n",
    "    cfg.t_start = t_start\n",
    "    cfg.t_end   = t_start + timedelta(hours=cfg.forecast_hours)\n",
    "    return cfg\n",
    "\n",
    "def print_config(cfg: Config) -> None:\n",
    "    print(\"\\nConjunction summary:\")\n",
    "\n",
    "    rows = {\n",
    "        \"Shell label\":              cfg.shell_name,\n",
    "        \"Object count\":             cfg.n_objects,\n",
    "        \"Time window\":              f\"{cfg.t_start} to {cfg.t_end}\",\n",
    "        \"Coarse step\":              f\"{cfg.coarse_step_minutes} min\",\n",
    "        \"Refine step\":              f\"{cfg.refine_step_seconds} sec\",\n",
    "        \"Coarse search radius\":     f\"{cfg.search_radius_km} km\",\n",
    "        \"Risk thresholds\":          f\"<{cfg.report_thresh_km} km, <{cfg.report_strict_km} km\",\n",
    "        \"Frame & units\":            \"SGP4 TEME/ECI; distances in km (Euclidean).\"\n",
    "    }\n",
    "    \n",
    "    for field, val in rows.items():\n",
    "        print(f\"{field}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df51eb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single shell detected:  500– 599 km\n",
      "\n",
      "Conjunction summary:\n",
      "Shell label:  500– 599 km\n",
      "Object count: 6093\n",
      "Time window: 2025-08-03 00:00:00+00:00 to 2025-08-04 00:00:00+00:00\n",
      "Coarse step: 5 min\n",
      "Refine step: 30 sec\n",
      "Coarse search radius: 20.0 km\n",
      "Risk thresholds: <10.0 km, <5.0 km\n",
      "Frame & units: SGP4 TEME/ECI; distances in km (Euclidean).\n"
     ]
    }
   ],
   "source": [
    "cfg = initialize_config(cfg, df_shell)\n",
    "print_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c9d1002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch freshness filter:\n",
      "  Window: |epoch - t_start| <= 1.0 days\n",
      "  Kept:     5874\n",
      "  Dropped:  219\n",
      "\n",
      "Age (days) among kept rows:\n",
      "count    5874.000000\n",
      "mean        0.148621\n",
      "std         0.355745\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n"
     ]
    }
   ],
   "source": [
    "# EPOCH FRESHNESS FILTER\n",
    "\n",
    "# goal: keep satellites whose TLE epoch is \"close\" to the common start time t_start.\n",
    "# avoids SGP4 numerical/pathology issues when propagating far from an object's own epoch\n",
    "\n",
    "# compute age of each epoch relative to t_start (days; positive means epoch BEFORE t_start)\n",
    "df_shell = df_shell.copy()\n",
    "df_shell[\"epoch_age_days\"] = (cfg.t_start - df_shell[\"epochDate\"]).dt.total_seconds() / 86400.0\n",
    "\n",
    "# pick a freshness window, like ±3 days for LEO screening\n",
    "max_age_days = 1.0\n",
    "\n",
    "fresh_mask = df_shell[\"epochDate\"].between(\n",
    "    cfg.t_start - pd.Timedelta(days=max_age_days),\n",
    "    cfg.t_start + pd.Timedelta(days=max_age_days)\n",
    ")\n",
    "\n",
    "df_shell_fresh = df_shell[fresh_mask].copy()\n",
    "\n",
    "print(\"Epoch freshness filter:\")\n",
    "print(f\"  Window: |epoch - t_start| <= {max_age_days:.1f} days\")\n",
    "print(f\"  Kept:     {len(df_shell_fresh)}\") \n",
    "print(f\"  Dropped:  {len(df_shell) - len(df_shell_fresh)}\")\n",
    "\n",
    "# summary of how far the kept epochs are from t_start\n",
    "print(\"\\nAge (days) among kept rows:\")\n",
    "print(df_shell_fresh['epoch_age_days'].describe().to_string())\n",
    " \n",
    "# if you dropped too many rows and want to relax the window - bump max_age_days to 5–7.\n",
    "# if you still drop a lot - consider redefining t_start (e.g., median/quantile of epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a7a83",
   "metadata": {},
   "source": [
    "## Build `SPG4` propagators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768a11c",
   "metadata": {},
   "source": [
    "`sgp4` is a standard model for predicting satellite positions from TLE data (two-line elements).\n",
    "\n",
    "Our dataframe doesn’t store raw tle strings, but it does have the equivalent parameters. \n",
    "We’ll feed those into `sgp4.api.Satrec` objects using the function `sgp4init`.\n",
    "\n",
    "Units and conversions:\n",
    "- `sgp4init` expects angles in radians, not degrees\n",
    "- `meanMotion` must be converted from revolutions/day to radians/minute\n",
    "- `epochDate` must be expressed as a Julian date split into (jd, fraction)\n",
    "\n",
    "Variable names (inclo, nodeo, argpo, mo, no_kozai, etc.) below were chosen to match the sgp4 C/fortran heritage.\n",
    "The python wrapper `sgp4.api` preserves those names for consistency.\n",
    "\n",
    "`sgp4init()` will return a satellite record object, called a `satrec`, that knows how to compute that satellite’s position at any time. `satellites` is a list where each element is dictionary containing a satellite's metadata and how to propagate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a155cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 6093 propagators successfully.\n"
     ]
    }
   ],
   "source": [
    "from sgp4.api import Satrec, SGP4_ERRORS, jday, WGS72\n",
    "\n",
    "satellites = []   # list of dictionaries with satNo, name, and Satrec object\n",
    "errors = []       # tracks any rows we fail to convert\n",
    "\n",
    "EPOCH0 = datetime(1949, 12, 31, 0, 0, 0, tzinfo=timezone.utc)\n",
    "\n",
    "for idx, row in df_shell.iterrows(): # loop through each row in df_shell\n",
    "    try:\n",
    "        epoch_dt = row[\"epochDate\"].to_pydatetime() # extract epoch as datetime\n",
    "\n",
    "        # days since 1949-12-31 (as float)\n",
    "        epoch_days = (epoch_dt - EPOCH0).total_seconds() / 86400.0\n",
    "\n",
    "        # convert to radians\n",
    "        inclo  = np.deg2rad(row[\"inclination_deg\"])\n",
    "        nodeo  = np.deg2rad(row[\"raan\"])\n",
    "        argpo  = np.deg2rad(row[\"argOfPerigee\"])\n",
    "        mo     = np.deg2rad(row[\"meanAnomaly\"])\n",
    "\n",
    "        # convert revs/day to rad/min\n",
    "        no_kozai = float(row[\"meanMotion\"]) * 2.0 * np.pi / (24.0 * 60.0)\n",
    "\n",
    "        # orbital scalers\n",
    "        ecco  = float(row[\"eccentricity\"])      # must be in [0,1)\n",
    "        bstar = float(row.get(\"bStar\", 0.0))    # ok if 0.0\n",
    "\n",
    "        # initialize satellite record\n",
    "        satrec = Satrec()\n",
    "        satrec.sgp4init(\n",
    "            WGS72,                 # Earth gravity model (standard for SGP4)\n",
    "            'i',                   # 'i' = initialize\n",
    "            int(row[\"satNo\"]),     # satellite ID\n",
    "            epoch_days,            # Julian date\n",
    "            bstar,                 # drag term\n",
    "            0.0, 0.0,              # ndot, nddot (not used here; 0.0 okay)\n",
    "            ecco,                  # eccentricity\n",
    "            argpo,                 # argument of perigee [rad]\n",
    "            inclo,                 # inclination [rad]\n",
    "            mo,                    # mean anomaly [rad]\n",
    "            no_kozai,              # mean motion [rad/min]\n",
    "            nodeo                  # RAAN [rad]\n",
    "        )\n",
    "\n",
    "        satellites.append({ # add satellite to list\n",
    "            \"satNo\": row[\"satNo\"],\n",
    "            \"satName\": row.get(\"satName\", \"\"),\n",
    "            \"objectType\": row.get(\"objectType\", \"\"),\n",
    "            \"satrec\": satrec\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        errors.append((idx, str(e)))\n",
    "\n",
    "print(f\"Built {len(satellites)} propagators successfully.\")\n",
    "if errors:\n",
    "    print(f\"Failed on {len(errors)} rows. Example error:\")\n",
    "    print(errors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e76afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 'FENGYUN 1C DEB' (satNo. 35230) at t_start=2025-08-03 00:00:00+00:00\n",
      "\n",
      "   r (km): [-4223.135, -905.095, -5454.942]\n",
      "   v (km/s): [5.25127, 2.94944, -4.5768]\n",
      "  |r|  = 6,957.76 km  (altitude ≈ 579.63 km above mean equator)\n",
      "  |v|  = 7.565 km/s\n",
      "\n",
      "Check: Values look reasonable for LEO ✅\n"
     ]
    }
   ],
   "source": [
    "# TEST PROPAGATION\n",
    "\n",
    "def norm3(vec):\n",
    "    return float(np.sqrt(vec[0]**2 + vec[1]**2 + vec[2]**2))\n",
    "    # returns Euclidean norm of a 3-vector\n",
    "\n",
    "# pick the first satellite we built\n",
    "if not satellites:\n",
    "    raise RuntimeError(\"No satellites in `satellites`, build propagators first\")\n",
    "test_sat = satellites[0]  # change index if desired\n",
    "\n",
    "# convert t_start to Julian date parts for SGP4\n",
    "jd, fr = jday(\n",
    "    cfg.t_start.year, \n",
    "    cfg.t_start.month,\n",
    "    cfg.t_start.day,\n",
    "    cfg.t_start.hour,\n",
    "    cfg.t_start.minute,\n",
    "    cfg.t_start.second + cfg.t_start.microsecond * 1e-6\n",
    ")\n",
    "\n",
    "# propagate and inspect results\n",
    "err, r, v = test_sat[\"satrec\"].sgp4(jd, fr)\n",
    "\n",
    "print(f\"Testing '{test_sat.get('satName','')}' (satNo. {test_sat['satNo']}) at t_start={cfg.t_start}\\n\")\n",
    "if err != 0:\n",
    "    print(f\"  SGP4 ERROR: {SGP4_ERRORS[err]}\")\n",
    "else:\n",
    "    # r, v are TEME/ECI position (km) and velocity (km/s)\n",
    "    r_mag = norm3(r)  # distance from Earth's center (km)\n",
    "    v_mag = norm3(v)  # speed (km/s)\n",
    "    alt_km = r_mag - cfg.earth_radius_km\n",
    "\n",
    "    print(\"   r (km):\", [round(x, 3) for x in r])\n",
    "    print(\"   v (km/s):\", [round(x, 5) for x in v])\n",
    "    print(f\"  |r|  = {r_mag:,.2f} km  (altitude ≈ {alt_km:,.2f} km above mean equator)\")\n",
    "    print(f\"  |v|  = {v_mag:,.3f} km/s\")\n",
    "\n",
    "    # LEO range check\n",
    "    if 6500 <= r_mag <= 7500 and 6.5 <= v_mag <= 8.5:\n",
    "        print(\"\\nCheck: Values look reasonable for LEO ✅\")\n",
    "    else:\n",
    "        print(\"\\nCheck: Values are unusual for LEO, recheck inputs ⚠️\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8adca00",
   "metadata": {},
   "source": [
    "## Coarse Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24712d",
   "metadata": {},
   "source": [
    "Build a time grid from `t_start` → `t_end` every `coarse_step_minutes`.\n",
    "\n",
    "For each time:\n",
    "- Propagate each satellite via `satrec.sgp4()` to get position `r = (x,y,z)` in TEME/ECI (km)\n",
    "- Build a KD-tree on the 3D positions\n",
    "- Query for all pairs within a search radius \n",
    "- Store those pairs as candidates with their coarse distance and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d3c1ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coarse grid has 289 timestamps \n",
      "(2025-08-03 00:00:00+00:00 to 2025-08-04 00:00:00+00:00, step=5 min)\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import cKDTree   # fast KD-tree (compiled)\n",
    "\n",
    "# returns Euclidean norm ||a-b|| if b is provided\n",
    "def norm3(a, b=None):\n",
    "    if b is None:\n",
    "        return float(np.sqrt((a*a).sum()))\n",
    "    d = a - b\n",
    "    return float(np.sqrt((d*d).sum()))\n",
    "\n",
    "times_coarse = pd.date_range( # build shared time grid\n",
    "    start = cfg.t_start,\n",
    "    end = cfg.t_end,\n",
    "    freq = f\"{cfg.coarse_step_minutes}min\",\n",
    "    inclusive = \"both\"  # include t_end\n",
    ").to_pydatetime().tolist()\n",
    "\n",
    "print(f\"Coarse grid has {len(times_coarse)} timestamps \"\n",
    "      f\"\\n({cfg.t_start} to {cfg.t_end}, step={cfg.coarse_step_minutes} min)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "181a18e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience arrays for satellite metadata\n",
    "n = len(satellites)\n",
    "satNos = np.array([int(s[\"satNo\"]) for s in satellites], dtype=np.int64)\n",
    "satNames = np.array([s.get(\"satName\",\"\") for s in satellites], dtype=object)\n",
    "\n",
    "candidates = [] # store in a list of dicts\n",
    "\n",
    "# simple progress printing every k steps\n",
    "print_every = max(1, len(times_coarse)//12)  # ~12 status lines over the run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5378f59a",
   "metadata": {},
   "source": [
    "## Neighbor Search (KD-tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d31c6a",
   "metadata": {},
   "source": [
    "Why use a KD-tree?\n",
    "\n",
    "It avoids O(N²) all-pairs checks. For ~6,000 satellites, all-pairs would be ~18M distance checks per timestep. KD-tree gives you only the nearby ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bae21497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=2025-08-03 00:00  cand=18896  total=18896\n",
      "t=2025-08-03 02:00  cand=21424  total=462047\n",
      "t=2025-08-03 04:00  cand=15567  total=886074\n",
      "t=2025-08-03 06:00  cand=20181  total=1310431\n",
      "t=2025-08-03 08:00  cand=15430  total=1725958\n",
      "t=2025-08-03 10:00  cand=19796  total=2145682\n",
      "t=2025-08-03 12:00  cand=15349  total=2556526\n",
      "t=2025-08-03 14:00  cand=19428  total=2977171\n",
      "t=2025-08-03 16:00  cand=15333  total=3384110\n",
      "t=2025-08-03 18:00  cand=19067  total=3797569\n",
      "t=2025-08-03 20:00  cand=15288  total=4200928\n",
      "t=2025-08-03 22:00  cand=18671  total=4612588\n",
      "t=2025-08-04 00:00  cand=15259  total=5011577\n"
     ]
    }
   ],
   "source": [
    "for t_idx, t in enumerate(times_coarse):\n",
    "    # convert this timestamp to Julian date parts\n",
    "    jd, fr = jday(t.year, t.month, t.day,\n",
    "                  t.hour, t.minute, t.second + t.microsecond * 1e-6)\n",
    "\n",
    "    # pre-allocate arrays for positions; mark invalid slots with NaN\n",
    "    R = np.full((n, 3), np.nan, dtype=float)\n",
    "    valid_mask = np.zeros(n, dtype=bool)\n",
    "\n",
    "    for i, s in enumerate(satellites): # propagate all satellites to time t\n",
    "        err, r, v = s[\"satrec\"].sgp4(jd, fr)\n",
    "        if err == 0:\n",
    "            R[i, :] = r  # km\n",
    "            valid_mask[i] = True\n",
    "        else:\n",
    "            if t_idx == 0 and i < 3:\n",
    "                print(\"sgp4 error:\", SGP4_ERRORS.get(err, err), \"for satNo\", s[\"satNo\"])\n",
    "\n",
    "    # keep only valid positions for the KD-tree\n",
    "    if not valid_mask.any():\n",
    "        continue # unlikely if epochs were filtered\n",
    "\n",
    "    Rv = R[valid_mask] # positions of valid satellites\n",
    "    idx_valid = np.where(valid_mask)[0] # lookup table, tells you which original satellite each row of Rv came from\n",
    "\n",
    "    tree = cKDTree(Rv) # build KD-tree and query all pairs within coarse search radius\n",
    "    pair_set = tree.query_pairs(r=cfg.search_radius_km) # returns indices (i, j) in the *compressed* array Rv\n",
    "\n",
    "    if not pair_set: # skip if zero candidates at this time\n",
    "        if t_idx % print_every == 0:\n",
    "            print(f\"t={t.isoformat()} candidates=0\")\n",
    "        continue\n",
    "\n",
    "    # for each candidate pair, compute the coarse distance and collect metadata\n",
    "    for (ia, ib) in pair_set:\n",
    "        gi = idx_valid[ia]  # global index into satellites list\n",
    "        gj = idx_valid[ib]\n",
    "\n",
    "        ra = Rv[ia]\n",
    "        rb = Rv[ib]\n",
    "        d_km = norm3(ra, rb)\n",
    "\n",
    "        # altitudes (quick context, not used as a filter here)\n",
    "        altA = norm3(ra) - cfg.earth_radius_km\n",
    "        altB = norm3(rb) - cfg.earth_radius_km\n",
    "\n",
    "        candidates.append({\n",
    "            \"t_coarse\": t,                # coarse timestamp\n",
    "            \"idxA\": gi, \"idxB\": gj,       # indices into `satellites` list\n",
    "            \"satNoA\": int(satNos[gi]),\n",
    "            \"satNoB\": int(satNos[gj]),\n",
    "            \"d_coarse_km\": d_km,\n",
    "            \"altA_km\": altA,\n",
    "            \"altB_km\": altB,\n",
    "        })\n",
    "\n",
    "    # PROGRESS LOG OPTIONS\n",
    "\n",
    "    # --- VERBOSE: print every timestep\n",
    "    # print(f\"[t={t:%Y-%m-%d %H:%M:%S}  cand={len(pair_set)}  total={len(candidates)}\")\n",
    "\n",
    "    # --- QUIET: only print when candidates exist\n",
    "    # if pair_set:\n",
    "    #     print(f\"HIT  t={t:%Y-%m-%d %H:%M}  +{len(pair_set)}  total={len(candidates)}\")\n",
    "\n",
    "    # --- LIGHT: periodic heartbeat (default)\n",
    "    if t_idx % print_every == 0:\n",
    "        print(f\"t={t:%Y-%m-%d %H:%M}  cand={len(pair_set)}  total={len(candidates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09184142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate preview:\n",
      "                 t_coarse  satNoA  satNoB  d_coarse_km    altA_km    altB_km\n",
      "2025-08-03 00:00:00+00:00   53215   53213     0.012744 566.036699 566.040957\n",
      "2025-08-03 00:00:00+00:00   48367   48374     0.014597 547.983245 547.995372\n",
      "2025-08-03 00:00:00+00:00   58190   56119     0.019235 558.789126 558.804504\n",
      "2025-08-03 00:00:00+00:00   55420   55271     0.026606 574.568089 574.590435\n",
      "2025-08-03 00:00:00+00:00   52858   52856     0.028376 540.663827 540.640100\n",
      "2025-08-03 00:00:00+00:00   56918   57997     0.032693 558.750160 558.735401\n",
      "2025-08-03 00:00:00+00:00   55435   55432     0.034817 574.578019 574.572876\n",
      "2025-08-03 00:00:00+00:00   58195   56134     0.040379 558.828136 558.830876\n",
      "2025-08-03 00:00:00+00:00   56699   57106     0.043731 558.911380 558.916606\n",
      "2025-08-03 00:00:00+00:00   64532   64531     0.055167 520.602541 520.578733\n",
      "\n",
      "Total coarse candidates collected: 5011577\n"
     ]
    }
   ],
   "source": [
    "candidates_df = pd.DataFrame(candidates)\n",
    "\n",
    "if candidates_df.empty:\n",
    "    print(\"\\nNo candidates found on the coarse grid, try increasing the search radius or extending the time window\")\n",
    "else:\n",
    "    # sort by time, then distance\n",
    "    candidates_df.sort_values([\"t_coarse\", \"d_coarse_km\"], inplace=True)\n",
    "\n",
    "    # preview\n",
    "    preview_cols = [\"t_coarse\", \"satNoA\", \"satNoB\", \"d_coarse_km\", \"altA_km\", \"altB_km\"]\n",
    "    print(\"\\nCandidate preview:\")\n",
    "    print(candidates_df[preview_cols].head(10).to_string(index=False))\n",
    "\n",
    "    print(f\"\\nTotal coarse candidates collected: {len(candidates_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6dd4cf",
   "metadata": {},
   "source": [
    "## Deduplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9c051",
   "metadata": {},
   "source": [
    "De-duplicate coarse candidates so we don’t refine the same pair many times. We'll keep the shortest coarse distance per unique pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e183627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique pairs to refine: 41670 (from 5011577 coarse rows)\n",
      "                 t_coarse  satNoA  satNoB  d_coarse_km\n",
      "2025-08-03 02:20:00+00:00   10095   43678    17.895829\n",
      "2025-08-03 07:40:00+00:00   42831   10096    18.119522\n",
      "2025-08-03 00:40:00+00:00   65055   10188    14.506981\n",
      "2025-08-03 10:15:00+00:00   10761   40290    12.681518\n",
      "2025-08-03 04:00:00+00:00   30879   10974    16.870528\n",
      "2025-08-03 01:30:00+00:00   34316   10974     7.241115\n",
      "2025-08-03 00:00:00+00:00   52377   11114    16.188481\n",
      "2025-08-03 00:25:00+00:00   11267   39416    17.834428\n",
      "2025-08-03 10:00:00+00:00   11267   43490    11.359098\n",
      "2025-08-03 00:45:00+00:00   11267   44886     5.931519\n"
     ]
    }
   ],
   "source": [
    "# check: ensure we have coarse candidates\n",
    "if 'candidates_df' not in locals() or candidates_df.empty:\n",
    "    raise RuntimeError(\"candidates_df is missing or empty.\")\n",
    "\n",
    "coarse = candidates_df.copy()\n",
    "\n",
    "# create an order-independent pair key\n",
    "pair_key = np.where(coarse[\"satNoA\"] < coarse[\"satNoB\"],\n",
    "                    coarse[\"satNoA\"].astype(str) + \"-\" + coarse[\"satNoB\"].astype(str),\n",
    "                    coarse[\"satNoB\"].astype(str) + \"-\" + coarse[\"satNoA\"].astype(str))\n",
    "coarse[\"pair_id\"] = pair_key\n",
    "\n",
    "# keep the closest coarse occurrence per pair\n",
    "# (to get multiple per pair across time, group by day/hour buckets later)\n",
    "coarse_best = (\n",
    "    coarse.sort_values([\"pair_id\", \"d_coarse_km\"])\n",
    "          .groupby(\"pair_id\", as_index=False)\n",
    "          .first()\n",
    ")\n",
    "\n",
    "print(f\"Unique pairs to refine: {len(coarse_best)} (from {len(coarse)} coarse rows)\")\n",
    "print(coarse_best[[\"t_coarse\",\"satNoA\",\"satNoB\",\"d_coarse_km\"]].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16e8f4",
   "metadata": {},
   "source": [
    "## Local Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776797a",
   "metadata": {},
   "source": [
    "Find true TCA and minimum distance! Steps:\n",
    "\n",
    "- For each unique pair, build a refinement time window centered on its coarse timestamp (e.g., ±10 minutes, step cfg.refine_step_seconds).\n",
    "\n",
    "- Propagate only those two satellites across the window.\n",
    "\n",
    "- Compute distance at each substep; pick the minimum → that’s the TCA and d_min.\n",
    "\n",
    "- Grab relative speed at TCA (from SGP4 velocities).\n",
    "\n",
    "- Save a tidy row for each refined event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c3c80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_pair(satA, satB, t_center, half_window_minutes=10, step_seconds=30):\n",
    " \n",
    "    # build the fine time grid centered at t_center\n",
    "    t_start = t_center - timedelta(minutes=half_window_minutes)\n",
    "    t_end   = t_center + timedelta(minutes=half_window_minutes)\n",
    "\n",
    "    # se seconds-based frequency (capital 'S')\n",
    "    times = pd.date_range(start=t_start, end=t_end,\n",
    "                          freq=f\"{step_seconds}S\", inclusive=\"both\").to_pydatetime()\n",
    "\n",
    "    # pre-allocate arrays for distances and relative speed\n",
    "    nT = len(times)\n",
    "    dists = np.full(nT, np.nan, dtype=float)\n",
    "    vrels = np.full(nT, np.nan, dtype=float)\n",
    "\n",
    "    # loop over sub-steps; propagate both sats and compute separation and rel speed\n",
    "    for k, tk in enumerate(times):\n",
    "        jd, fr = jday(tk.year, tk.month, tk.day,\n",
    "                      tk.hour, tk.minute, tk.second + tk.microsecond * 1e-6)\n",
    "\n",
    "        errA, rA, vA = satA[\"satrec\"].sgp4(jd, fr)\n",
    "        errB, rB, vB = satB[\"satrec\"].sgp4(jd, fr)\n",
    "\n",
    "        if errA != 0 or errB != 0:\n",
    "            # skip this sub-step if either failed (can happen near stale epochs)\n",
    "            continue\n",
    "\n",
    "        # distance between positions (km)\n",
    "        dists[k] = norm3(np.array(rA) - np.array(rB))\n",
    "\n",
    "        # relative speed magnitude (km/s)\n",
    "        rel_v = np.array(vA) - np.array(vB)\n",
    "        vrels[k] = norm3(rel_v)\n",
    "\n",
    "    # choose minimum valid distance\n",
    "    if np.all(np.isnan(dists)):\n",
    "        return {\n",
    "            \"satNoA\": satA[\"satNo\"], \"satNoB\": satB[\"satNo\"],\n",
    "            \"satNameA\": satA.get(\"satName\",\"\"), \"satNameB\": satB.get(\"satName\",\"\"),\n",
    "            \"t_TCA\": None, \"d_min_km\": np.nan, \"v_rel_km_s\": np.nan,\n",
    "            \"t_center\": t_center, \"n_steps\": nT,\n",
    "            \"status\": \"refine_failed_all_nan\"\n",
    "        }\n",
    "\n",
    "    kmin = np.nanargmin(dists)\n",
    "    return {\n",
    "        \"satNoA\": satA[\"satNo\"], \"satNoB\": satB[\"satNo\"],\n",
    "        \"satNameA\": satA.get(\"satName\",\"\"), \"satNameB\": satB.get(\"satName\",\"\"),\n",
    "        \"t_TCA\": times[kmin],\n",
    "        \"d_min_km\": float(dists[kmin]),\n",
    "        \"v_rel_km_s\": float(vrels[kmin]) if not np.isnan(vrels[kmin]) else np.nan,\n",
    "        \"t_center\": t_center, # coarse time around which we refine\n",
    "\n",
    "        \"n_steps\": nT,\n",
    "        \"status\": \"ok\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b8f5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ash\\AppData\\Local\\Temp\\ipykernel_13912\\2767047286.py:8: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  times = pd.date_range(start=t_start, end=t_end,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement complete. Rows: 41670\n",
      " satNoA  satNoB        satNameA    satNameB                     t_TCA  d_min_km  v_rel_km_s                  t_center  n_steps status\n",
      "  10095   43678      COSMOS 921   DIWATA 2B 2025-08-03 02:20:00+00:00 17.895829    3.029118 2025-08-03 02:20:00+00:00       41     ok\n",
      "  42831   10096   FLYING LAPTOP   SL-14 R/B 2025-08-03 07:40:00+00:00 18.119522   11.653229 2025-08-03 07:40:00+00:00       41     ok\n",
      "  65055   10188         PRSC-S1 DELTA 1 DEB 2025-08-03 00:40:00+00:00 14.506981    1.997945 2025-08-03 00:40:00+00:00       41     ok\n",
      "  10761   40290     DELTA 1 DEB   CZ-2C DEB 2025-08-03 10:15:00+00:00 12.681518   14.566158 2025-08-03 10:15:00+00:00       41     ok\n",
      "  30879   10974  FENGYUN 1C DEB   SL-14 R/B 2025-08-03 04:00:00+00:00 16.870528   15.185883 2025-08-03 04:00:00+00:00       41     ok\n",
      "  34316   10974 COSMOS 2251 DEB   SL-14 R/B 2025-08-03 01:30:00+00:00  7.241115    1.227373 2025-08-03 01:30:00+00:00       41     ok\n",
      "  52377   11114   STARLINK-3805    SL-8 DEB 2025-08-03 00:00:00+00:00 16.188481    2.736324 2025-08-03 00:00:00+00:00       41     ok\n",
      "  11267   39416       SL-14 R/B APRIZESAT 7 2025-08-03 00:25:00+00:00 17.834428   13.970884 2025-08-03 00:25:00+00:00       41     ok\n",
      "  11267   43490       SL-14 R/B   CZ-2D DEB 2025-08-03 10:00:00+00:00 11.359098    7.671557 2025-08-03 10:00:00+00:00       41     ok\n",
      "  11267   44886       SL-14 R/B    OBJECT H 2025-08-03 00:45:00+00:00  5.931519    2.051345 2025-08-03 00:45:00+00:00       41     ok\n"
     ]
    }
   ],
   "source": [
    "refined_rows = []\n",
    "half_window_minutes = 10    # ±10 minutes around the coarse time\n",
    "step_seconds = cfg.refine_step_seconds\n",
    "\n",
    "for _, row in coarse_best.iterrows():\n",
    "    iA = int(row[\"idxA\"])   # indices into satellites\n",
    "    iB = int(row[\"idxB\"])\n",
    "    t_center = pd.to_datetime(row[\"t_coarse\"], utc=True).to_pydatetime()\n",
    "\n",
    "    satA = satellites[iA]\n",
    "    satB = satellites[iB]\n",
    "\n",
    "    result = refine_pair(\n",
    "        satA, satB, t_center,\n",
    "        half_window_minutes=half_window_minutes,\n",
    "        step_seconds=step_seconds\n",
    "    )\n",
    "    refined_rows.append(result)\n",
    "\n",
    "refined_df = pd.DataFrame(refined_rows)\n",
    "\n",
    "print(f\"Refinement complete. Rows: {len(refined_df)}\")\n",
    "print(refined_df.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b880a7",
   "metadata": {},
   "source": [
    "### `status` column tags: `ok` or `fail`\n",
    "\n",
    "Not every coarse candidate can be successfully refined. Common reasons:\n",
    "\n",
    "- bad/missing TLE parameters for one of the objects\n",
    "- numerical failure in the propagator\n",
    "- epochs too far out of date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbb31ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41670 entries, 0 to 41669\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   satNoA      41670 non-null  int64              \n",
      " 1   satNoB      41670 non-null  int64              \n",
      " 2   satNameA    41670 non-null  object             \n",
      " 3   satNameB    41670 non-null  object             \n",
      " 4   t_TCA       41670 non-null  datetime64[ns, UTC]\n",
      " 5   d_min_km    41670 non-null  float64            \n",
      " 6   v_rel_km_s  41670 non-null  float64            \n",
      " 7   t_center    41670 non-null  datetime64[ns, UTC]\n",
      " 8   n_steps     41670 non-null  int64              \n",
      " 9   status      41670 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(3), object(3)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# drop rows where refinement failed completely\n",
    "events_df = refined_df[refined_df[\"status\"] == \"ok\"].copy()\n",
    "events_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbfd6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refinement results:\n",
      "  Total coarse candidates: 41670\n",
      "  Successful refinements:  41670 (100.0%)\n",
      "  Failed refinements:      0\n"
     ]
    }
   ],
   "source": [
    "total = len(refined_df) # total coarse candidates refined\n",
    "\n",
    "status_counts = refined_df[\"status\"].value_counts()\n",
    "\n",
    "success = status_counts.get(\"ok\", 0) \n",
    "fail = total - success\n",
    "success_rate = 100.0 * success / total if total > 0 else 0.0\n",
    "\n",
    "print(f\"Refinement results:\")\n",
    "print(f\"  Total coarse candidates: {total}\")\n",
    "print(f\"  Successful refinements:  {success} ({success_rate:.1f}%)\")\n",
    "print(f\"  Failed refinements:      {fail}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba960eaa",
   "metadata": {},
   "source": [
    "## Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e9f7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply thresholds\n",
    "events_df[\"below_10km\"] = events_df[\"d_min_km\"] < cfg.report_thresh_km\n",
    "events_df[\"below_5km\"]  = events_df[\"d_min_km\"] < cfg.report_strict_km\n",
    "\n",
    "events_10 = events_df[events_df[\"below_10km\"]].copy()\n",
    "events_5 = events_df[events_df[\"below_5km\"]].copy()\n",
    "\n",
    "# sort by TCA then by distance\n",
    "events_10.sort_values([\"t_TCA\", \"d_min_km\"], inplace=True)\n",
    "events_5.sort_values([\"t_TCA\", \"d_min_km\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c34eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events under 10.0 km: 20307\n",
      "Events under 5.0 km:  12959\n",
      "\n",
      "                    t_TCA  satNoA  satNoB  d_min_km  v_rel_km_s\n",
      "2025-08-02 23:50:00+00:00   52092   52310  0.045807    0.000165\n",
      "2025-08-02 23:50:00+00:00   63096   63080  0.143227    0.000305\n",
      "2025-08-02 23:50:00+00:00   64544   64543  0.191631    0.000303\n",
      "2025-08-02 23:50:00+00:00   62712   62706  0.350875    0.000761\n",
      "2025-08-02 23:50:00+00:00   64092   64090  0.383235    0.000776\n",
      "2025-08-02 23:50:00+00:00   56349   56352  0.391792    0.000352\n",
      "2025-08-02 23:50:00+00:00   51758   51756  0.482989    0.000531\n",
      "2025-08-02 23:50:00+00:00   58211   58218  0.519249    0.000640\n",
      "2025-08-02 23:50:00+00:00   64155   64166  0.600434    0.001913\n",
      "2025-08-02 23:50:00+00:00   51152   51754  0.621888    0.000807\n"
     ]
    }
   ],
   "source": [
    "print(f\"Events under {cfg.report_thresh_km} km: {len(events_10)}\")\n",
    "print(f\"Events under {cfg.report_strict_km} km:  {len(events_5)}\\n\")\n",
    "\n",
    "preview_cols = [\"t_TCA\",\"satNoA\",\"satNoB\",\"d_min_km\",\"v_rel_km_s\"]\n",
    "print(events_5[preview_cols].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9af4bf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily counts (<10 km): \n",
      "date\n",
      "2025-08-02 00:00:00+00:00      173\n",
      "2025-08-03 00:00:00+00:00    20132\n",
      "2025-08-04 00:00:00+00:00        2\n",
      "dtype: int64\n",
      "\n",
      "Daily counts (<5 km): \n",
      "date\n",
      "2025-08-02 00:00:00+00:00      115\n",
      "2025-08-03 00:00:00+00:00    12842\n",
      "2025-08-04 00:00:00+00:00        2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count by day/hour (for multi-day runs)\n",
    "events_10[\"date\"] = events_10[\"t_TCA\"].dt.floor(\"D\")\n",
    "daily_counts = events_10.groupby(\"date\").size()\n",
    "print(f\"Daily counts (<10 km): \\n{daily_counts}\")\n",
    "\n",
    "# count by day/hour (for multi-day runs)\n",
    "events_5[\"date\"] = events_5[\"t_TCA\"].dt.floor(\"D\")\n",
    "daily_counts = events_5.groupby(\"date\").size()\n",
    "print(f\"\\nDaily counts (<5 km): \\n{daily_counts}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7cc991",
   "metadata": {},
   "source": [
    "## Which object types dominate conjunction risk?\n",
    "\n",
    "- by pair count\n",
    "- by weighted risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300895cf",
   "metadata": {},
   "source": [
    "### By pair count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cad71d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41670 entries, 0 to 41669\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype              \n",
      "---  ------      --------------  -----              \n",
      " 0   satNoA      41670 non-null  int64              \n",
      " 1   satNoB      41670 non-null  int64              \n",
      " 2   satNameA    41670 non-null  object             \n",
      " 3   satNameB    41670 non-null  object             \n",
      " 4   t_TCA       41670 non-null  datetime64[ns, UTC]\n",
      " 5   d_min_km    41670 non-null  float64            \n",
      " 6   v_rel_km_s  41670 non-null  float64            \n",
      " 7   t_center    41670 non-null  datetime64[ns, UTC]\n",
      " 8   n_steps     41670 non-null  int64              \n",
      " 9   status      41670 non-null  object             \n",
      " 10  pair_id     41670 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](2), float64(2), int64(3), object(4)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_events = events_df.copy()\n",
    "\n",
    "# normalize pair ID so A-B and B-A collapse to the same key\n",
    "pair_id_refined = np.where(df_events[\"satNoA\"] < df_events[\"satNoB\"],\n",
    "                           df_events[\"satNoA\"].astype(str) + \"-\" + df_events[\"satNoB\"].astype(str),\n",
    "                           df_events[\"satNoB\"].astype(str) + \"-\" + df_events[\"satNoA\"].astype(str))\n",
    "df_events[\"pair_id\"] = pair_id_refined\n",
    "\n",
    "df_events.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "013a0c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_events</th>\n",
       "      <th>median_miss_km</th>\n",
       "      <th>min_miss_km</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Payload–Payload</th>\n",
       "      <td>38713</td>\n",
       "      <td>10.145515</td>\n",
       "      <td>0.006495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payload–Unknown</th>\n",
       "      <td>958</td>\n",
       "      <td>10.452237</td>\n",
       "      <td>0.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debris–Payload</th>\n",
       "      <td>910</td>\n",
       "      <td>14.500108</td>\n",
       "      <td>0.411050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown–Unknown</th>\n",
       "      <td>494</td>\n",
       "      <td>7.407047</td>\n",
       "      <td>0.030465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Payload–Rocket body</th>\n",
       "      <td>293</td>\n",
       "      <td>14.086566</td>\n",
       "      <td>0.265819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debris–Debris</th>\n",
       "      <td>193</td>\n",
       "      <td>12.881185</td>\n",
       "      <td>1.183780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debris–Rocket body</th>\n",
       "      <td>43</td>\n",
       "      <td>14.850467</td>\n",
       "      <td>4.545728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debris–Unknown</th>\n",
       "      <td>37</td>\n",
       "      <td>12.814541</td>\n",
       "      <td>1.015493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocket body–Unknown</th>\n",
       "      <td>19</td>\n",
       "      <td>13.422841</td>\n",
       "      <td>1.979328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rocket body–Rocket body</th>\n",
       "      <td>10</td>\n",
       "      <td>18.328455</td>\n",
       "      <td>2.595006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         n_events  median_miss_km  min_miss_km\n",
       "pair_type                                                     \n",
       "Payload–Payload             38713       10.145515     0.006495\n",
       "Payload–Unknown               958       10.452237     0.110107\n",
       "Debris–Payload                910       14.500108     0.411050\n",
       "Unknown–Unknown               494        7.407047     0.030465\n",
       "Payload–Rocket body           293       14.086566     0.265819\n",
       "Debris–Debris                 193       12.881185     1.183780\n",
       "Debris–Rocket body             43       14.850467     4.545728\n",
       "Debris–Unknown                 37       12.814541     1.015493\n",
       "Rocket body–Unknown            19       13.422841     1.979328\n",
       "Rocket body–Rocket body        10       18.328455     2.595006"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map satNo -> objectType\n",
    "id_to_type = df_shell.set_index(\"satNo\")[\"objectType\"]\n",
    "\n",
    "# annotate conjunction pairs with object types\n",
    "df_conj = df_events.assign(\n",
    "    type1 = df_events[\"satNoA\"].map(id_to_type),\n",
    "    type2 = df_events[\"satNoB\"].map(id_to_type)\n",
    ").copy()\n",
    "\n",
    "# categorize the pair (order independent)\n",
    "def pair_category(row):\n",
    "    t1, t2 = sorted([row[\"type1\"], row[\"type2\"]])\n",
    "    return f\"{t1}–{t2}\"\n",
    "\n",
    "df_conj[\"pair_type\"] = df_conj.apply(pair_category, axis=1)\n",
    "\n",
    "# aggregate\n",
    "pair_summary = (\n",
    "    df_conj.groupby(\"pair_type\")\n",
    "           .agg(\n",
    "               n_events=(\"d_min_km\", \"size\"),\n",
    "               median_miss_km=(\"d_min_km\", \"median\"),\n",
    "               min_miss_km=(\"d_min_km\", \"min\")\n",
    "           )\n",
    "           .sort_values(\"n_events\", ascending=False)\n",
    ")\n",
    "pair_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc2b1f",
   "metadata": {},
   "source": [
    "### By weighted risk \n",
    "\n",
    "We want close approaches to count more heavily than distant ones.\n",
    "\n",
    "- 0.1 km miss → weight = 10\n",
    "- 1.0 km miss → weight = 1\n",
    "- 10 km miss → weight = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8214f2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weighted_risk</th>\n",
       "      <th>n_involved</th>\n",
       "      <th>median_miss_km</th>\n",
       "      <th>risk_share_%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Satellite</th>\n",
       "      <td>57361.437666</td>\n",
       "      <td>39021</td>\n",
       "      <td>2.937914</td>\n",
       "      <td>98.765540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>614.700760</td>\n",
       "      <td>1116</td>\n",
       "      <td>4.963081</td>\n",
       "      <td>1.058398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Debris</th>\n",
       "      <td>102.253902</td>\n",
       "      <td>477</td>\n",
       "      <td>6.815291</td>\n",
       "      <td>0.176062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           weighted_risk  n_involved  median_miss_km  risk_share_%\n",
       "bucket                                                            \n",
       "Satellite   57361.437666       39021        2.937914     98.765540\n",
       "Unknown       614.700760        1116        4.963081      1.058398\n",
       "Debris        102.253902         477        6.815291      0.176062"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map to buckets\n",
    "bucket_map = {\"Payload\":\"Satellite\", \"Rocket body\":\"Debris\", \"Debris\":\"Debris\", \"Unknown\":\"Unknown\"}\n",
    "dfw2 = dfw.copy()\n",
    "dfw2[\"bucket1\"] = dfw2[\"type1\"].map(bucket_map).fillna(\"Other/Unknown\")\n",
    "dfw2[\"bucket2\"] = dfw2[\"type2\"].map(bucket_map).fillna(\"Other/Unknown\")\n",
    "\n",
    "# stack both sides so each event counts for both participants\n",
    "tall = pd.concat([\n",
    "    dfw2[[MISS_COL, \"bucket1\"]].rename(columns={\"bucket1\":\"bucket\"}),\n",
    "    dfw2[[MISS_COL, \"bucket2\"]].rename(columns={\"bucket2\":\"bucket\"})\n",
    "], ignore_index=True)\n",
    "\n",
    "# recompute weights on the stacked view\n",
    "tall[\"weight\"] = 1.0 / (tall[MISS_COL] + EPS)\n",
    "\n",
    "side_risk = (\n",
    "    tall.groupby(\"bucket\")\n",
    "        .agg(\n",
    "            weighted_risk=(\"weight\", \"sum\"),\n",
    "            n_involved=(\"bucket\", \"size\"),\n",
    "            median_miss_km=(MISS_COL, \"median\")\n",
    "        )\n",
    "        .sort_values(\"weighted_risk\", ascending=False)\n",
    ")\n",
    "\n",
    "side_risk[\"risk_share_%\"] = 100.0 * side_risk[\"weighted_risk\"] / side_risk[\"weighted_risk\"].sum()\n",
    "side_risk\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wid_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
